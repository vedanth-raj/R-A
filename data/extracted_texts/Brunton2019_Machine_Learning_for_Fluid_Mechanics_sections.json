{
  "sections": [
    {
      "title": "Abstract",
      "content": "The \ufb01eld of \ufb02uid mechanics is rapidly advancing, driven by unprece-\ndented volumes of data from \ufb01eld measurements, experiments and large-\nscale simulations at multiple spatiotemporal scales. Machine learning\no\ufb00ers a wealth of techniques to extract information from data that\ncould be translated into knowledge about the underlying \ufb02uid me-\nchanics. Moreover, machine learning algorithms can augment domain\nknowledge and automate tasks related to \ufb02ow control and optimiza-\ntion. This article presents an overview of past history, current devel-\nopments, and emerging opportunities of machine learning for \ufb02uid me-\nchanics. It outlines fundamental machine learning methodologies and\ndiscusses their uses for understanding, modeling, optimizing, and con-\ntrolling \ufb02uid \ufb02ows. The strengths and limitations of these methods are\naddressed from the perspective of scienti\ufb01c inquiry that considers data\nas an inherent part of modeling, experimentation, and simulation. Ma-\nchine learning provides a powerful information processing framework\nthat can enrich, and possibly even transform, current lines of \ufb02uid me-\nchanics research and industrial applications.\n1\narXiv:1905.11075v3  [physics.flu-dyn]  4 Jan 2020",
      "type": "abstract",
      "word_count": 168
    },
    {
      "title": "1. INTRODUCTION",
      "content": "Fluid mechanics has traditionally dealt with massive amounts of data from experiments,\n\ufb01eld measurements, and large-scale numerical simulations. Big data has been a reality in\n\ufb02uid mechanics (Pollard et al. 2016) over the last decade due to high-performance comput-\ning architectures and advances in experimental measurement capabilities. Over the past 50\nyears many techniques were developed to handle data of \ufb02uid \ufb02ows, ranging from advanced\nalgorithms for data processing and compression, to databases of turbulent \ufb02ow \ufb01elds (Perl-\nman et al. 2007; Wu & Moin 2008). However, the analysis of \ufb02uid mechanics data has relied\n,to a large extent, on domain expertise, statistical analysis, and heuristic algorithms.\nMassive amounts of data is today widespread across scienti\ufb01c disciplines, and gaining\ninsight and actionable information from them has become a new mode of scienti\ufb01c inquiry\nas well as a commercial opportunity. Our generation is experiencing an unprecedented con-\n\ufb02uence of 1) vast and increasing volumes of data, 2) advances in computational hardware\nand reduced costs for computation, data storage and transfer, 3) powerful algorithms, 4) an\nabundance of open source software and benchmark problems, and 5) signi\ufb01cant and ongo-\ning investment by industry on data driven problem solving. These advances have, in turn,\nfueled renewed interest and progress in the \ufb01eld of machine learning (ML). Machine learn-\ning algorithms (here categorized as supervised, semi-supervised, and unsupervised learning\n(see Fig. 1) are rapidly making inroads in \ufb02uid mechanics. Machine learning provides a\nmodular and agile modeling framework that can be tailored to address many challenges\nin \ufb02uid mechanics, such as reduced-order modeling, experimental data processing, shape\noptimization, turbulence closure, and control. As scienti\ufb01c inquiry increasingly shifts from\n\ufb01rst principles to data-driven approaches, we may draw a parallel between current e\ufb00orts\nin machine learning with the development of numerical methods in the 1940\u2019s and 1950\u2019s\nto solve the equations of \ufb02uid dynamics. Fluid mechanics stands to bene\ufb01t from learning\nalgorithms and in return present challenges that may further advance these algorithms to\ncomplement human understanding and engineering intuition.\nMachine learning:\nAlgorithms that\nextract patterns and\ninformation from\ndata. They facilitate\nautomation and can\naugment human\ndomain knowledge.\nIn this review, in addition to outlining successes, we emphasize the importance of un-\nderstanding how learning algorithms work and when these methods succeed or fail. It is\nimportant to balance excitement about the capabilities of machine learning with the reality\nthat its application to \ufb02uid mechanics is an open and challenging \ufb01eld. In this context,\nwe also highlight the bene\ufb01t of incorporating domain knowledge about \ufb02uid mechanics into\nlearning algorithms. We envision that the \ufb02uid mechanics community can contribute to\nadvances in machine learning reminiscent of the advances in numerical methods in the last\ncentury.\n1.1. Historical Overview\nMachine learning and \ufb02uid dynamics share a long, and possibly surprising, history of inter-\nfaces. In the early 1940\u2019s Kolmogorov, a founder of statistical learning theory, considered\nturbulence as one of its prime application domains (Kolmogorov 1941). Advances in ma-\nchine learning in the 1950\u2019s and 1960\u2019s were characterized by two distinct developments. On\none side we distinguish cybernetics (Wiener 1965) and expert systems designed to emulate\nthe thinking process of the human brain, and on the other \u201cmachines\u201d like the percep-\ntron (Rosenblatt 1958) aimed to automate processes such as classi\ufb01cation and regression.\nAdvances on the second branch are also prevailing today and it is understandable how the\nuse of perceptrons for classi\ufb01cation created signi\ufb01cant excitement for Arti\ufb01cial Intelligence\n2\nBrunton, Noack, and Koumoutsakos\n\n\n\u2022SVM, \n\u2022Decision trees,\n\u2022Random forests,\n\u2022Neural Networks \n\u2026\n\u2022POD/PCA,\n\u2022Autoencoder, \n\u2022Self-organiz. maps, \n\u2022Diffusion maps\n\u2026 \n\u2022K-means, \u2028\nK nearest neighb.,\n\u2022Spectral \nclustering,\n...\n\u2022Q-learning, \n\u2022Markov decision \nprocesses,\n\u2022Deep RL\n\u2026\n\u2022Generative \nadversarial \nnetworks (GANs)\n\u2026\n\u2022 Linear control,\n\u2022 Genetic algorithms,\n\u2022Deep MPC, \n\u2026\n\u2022Linear, \n\u2022 Generalized linear,\n\u2022Gaussian process, \n\u2026\nSupervised\nSemi-supervised\nUn-supervised\nClassi\ufb01cation\nRegression\nOptimization \n& Control\nReinforcement \nLearning\nGenerative \nModels\nClustering\nDimensionality \nReduction\nFigure 1\nMachine learning algorithms may be categorized into supervised, unsupervised, and semi-supervised, depending on the\nextent and type of information available for the learning process.\n(AI) in the early 50\u2019s. However, this excitement was quenched by \ufb01ndings that their capa-\nbilities had severe limitations (Minsky & Papert 1969): single layer perceptrons were only\nable to learn linearly separable functions and not capable of learning the XOR function. It\nwas known that multi-layer perceptrons could learn the XOR function, but perhaps their\nadvancement was limited given the computational resources of the times (a recurring theme\nin Machine Learning research). The reduced interest in perceptrons was soon accompanied\nby a reduced interest in AI in general.\nPerceptron: The \ufb01rst\nlearning machine: A\ncomposition of\nbinary decision units\nused for\nclassi\ufb01cation.\nAnother branch of machine learning, closely related to the budding ideas of cybernetics\nin the early 1960\u2019s, was pioneered by two graduate students: Ingo Rechenberg and Hans-\nPaul Schwefel at TU Berlin. They performed experiments in a wind tunnel on a corrugated\nstructure composed of 5 linked plates with the goal of \ufb01nding their optimal angles to re-\nduce the overall drag (see Fig. 2). Their breakthrough involved adding random variations\nto these angles, where the randomness was generated using a Galton board (an \u201canalog\u201d\nrandom number generator). Most importantly, the size of the variance was learned (in-\ncreased/decreased) based on the success rate (positive/negative) of the experiments. The\nwork of Rechenberg and Schwefel has received little recognition, even though over the last\ndecades a signi\ufb01cant number of applications in \ufb02uid mechanics and aerodynamics use ideas\nthat can be traced back to their work. Renewed interest in the potential of AI for aero-\ndynamics applications materialized almost simultaneously with the early developments in\ncomputational \ufb02uid dynamics in the early 1980\u2019s. Attention was given to expert systems\nto assist in aerodynamic design and development processes (Mehta & Kutler 1984).\nAn indirect link between \ufb02uid mechanics and machine learning was the so-called\n\u201cLighthill report\u201d in 1974 that criticized arti\ufb01cial intelligence programs in the UK, as not\ndelivering on their grand claims. This report played a major role in the reduced funding and\ninterest in AI in the UK and subsequently in the USA, known as the AI winter. Lighthill\u2019s\nmain argument was based on his perception that AI would never be able to address the\nchallenge of the combinatorial explosion between possible con\ufb01gurations in the parameter\nspace. He used the limitations of language processing systems of that time as a key demon-\nstration of that failure for AI. In Lighthill\u2019s defense, 40 years ago the powers of modern\ncomputers as we know them today may have been di\ufb03cult to fathom. Indeed today one\nmay watch Lighthill\u2019s speech against AI on the internet while a machine learning algorithm\nautomatically provides the captions.\nThe reawakening of interest in machine learning, and in neural networks in particular,\ncame in the late 1980\u2019s with the development of the back-propagation algorithm (Rumel-\nhart et al. 1986). This enabled the training of neural networks with multiple layers, even\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n3\n\n\nFigure 2\nFirst example of learning and automation in experimental \ufb02uid mechanics: Rechenberg\u2019s\nexperiments for optimally corrugated plates for drag reduction using the Galtonbrett (Galton\nboard) as an analog random number generator (Rechenberg 1964).\nthough in the early days at most two layers were the norm. Another source of stimulus\nwere the works by Hop\ufb01eld (1982); Gardner (1988); Hinton & Sejnowski (1986) who devel-\noped links between machine learning algorithms and statistical mechanics. However, these\ndevelopments did not attract many researchers from \ufb02uid mechanics.\nIn the early 1990\u2019s a number of applications of neural networks in \ufb02ow-related problems\nwere developed in the context of trajectory analysis and classi\ufb01cation for particle tracking\nvelocimetry (PTV) and particle image velocimetry (PIV) (Teo et al. 1991; Grant & Pan\n1995) as well as to identify phase con\ufb01gurations in multi-phase \ufb02ows (Bishop & James 1993).\nThe link between POD and linear neural networks (Baldi & Hornik 1989) was exploited\nin order to reconstruct turbulence \ufb02ow \ufb01elds and the \ufb02ow in the near wall region of a\nchannel \ufb02ow using wall only information (Milano & Koumoutsakos 2002). This application\nintroduced multiple layers of neurons to improve compression results, marking perhaps the\n\ufb01rst use of deep learning, as it is known today, in the \ufb01eld of \ufb02uid mechanics.\nIn the past few years we have experienced a renewed blossoming of machine learning\napplications in \ufb02uid mechanics. Much of this interest is attributed to the remarkable perfor-\nmance of deep learning architectures, which hierarchically extract informative features from\ndata. This has led to several advances in data rich and model limited \ufb01elds, such as social\nsciences, and in companies for which prediction is a key \ufb01nancial factor. Fluid mechanics is\nnot model-limited and is rapidly becoming a data rich \ufb01eld. We believe that this con\ufb02uence\nof \ufb01rst principles and data-driven approaches is unique and has the potential to transform\nboth \ufb02uid mechanics and machine learning.\n1.2. Challenges and Opportunities for Machine Learning in Fluid Dynamics\nFluid dynamics presents challenges that di\ufb00er from those tackled in many applications of\nmachine learning, such as image recognition and advertising. In \ufb02uid \ufb02ows it is often im-\nportant to precisely quantify the underlying physical mechanisms in order to analyze them.\nFurthermore, \ufb02uids \ufb02ows entail complex, multi-scale phenomena whose understanding and\ncontrol remain to a large extent unresolved. Unsteady \ufb02ow \ufb01elds require algorithms capable\nof addressing nonlinearities and multiple spatiotemporal scales that may not be present in\npopular machine learning algorithms.\nIn addition, many prominent applications of ma-\nchine learning, such as playing video games, rely on inexpensive system evaluations and\nan exhaustive categorization of the process that must be learned. This is not the case in\n\ufb02uids, where experiments may be di\ufb03cult to repeat or automate and where simulations\nmay require large-scale supercomputers operating for extended periods of time.\nMachine learning has also become instrumental in robotics, and algorithms such as\nreinforcement learning are used routinely in autonomous driving and \ufb02ight. While many\nrobots operate in \ufb02uids, it appears that the subtleties of \ufb02uid dynamics are not presently\na major concern in their design. Reminiscent of the pioneering days of \ufb02ight, solutions\n4\nBrunton, Noack, and Koumoutsakos\n\n\nimitating natural forms and processes are often the norm (see the sidebar titled \u201dLearning\nFluid Mechanics: From Living Organisms to Machines\u201d).\nWe believe, that the deeper\nunderstanding and exploitation of \ufb02uid mechanics will become critical in the design of\nrobotic devices, when their energy consumption and reliability in complex \ufb02ow environments\nbecome a concern.\nInterpretability: The\ndegree to which a\nmodel may be\nunderstood or\ninterpreted by an\nexpert human.\nGeneralizability: The\nability of a model to\ngeneralize to new\nexamples including\nunseen data.\nNewton\u2019s second law\nis an example.\nIn the context of \ufb02ow control, actively or passively manipulating \ufb02ow dynamics for an\nengineering objective may change the nature of the system, making predictions, based on\ndata of uncontrolled systems, impossible. Although \ufb02uid data is vast in some dimensions,\nsuch as spatial resolution, it may be sparse in others; e.g., it may be expensive to perform\nparametric studies. Furthermore, \ufb02uids data can be highly heterogeneous, requiring special\ncare when choosing the type of learning machine.\nIn addition, many \ufb02uid systems are\nnon-stationary, and even for stationary \ufb02ows it may be prohibitively expensive to obtain\nstatistically converged results.\nFluid dynamics are central to transportation, health, and defense systems, and it is,\ntherefore, essential that machine learning solutions are interpretable, explainable, and gen-\neralizable. Moreover, it is often necessary to provide guarantees on performance, which are\npresently rare. Indeed, there is a poignant lack of convergence results, analysis, and guar-\nantees in many machine learning algorithms. It is also important to consider whether the\nmodel will be used for interpolation within a parameter regime or for extrapolation, which\nis considerably more challenging. Finally, we emphasize the importance of cross-validation\non withheld data sets to prevent over\ufb01tting in machine learning.\nWe suggest that this, non-exhaustive, list of challenges need not be a barrier; to the\ncontrary, it should provide a strong motivation for the development of more e\ufb00ective ma-\nchine learning techniques. These techniques will likely impact a number of disciplines if\nthey are able to solve \ufb02uid mechanics problems. For example, the application of machine\nlearning to systems with known physics, such as \ufb02uid mechanics, may provide deeper the-\noretical insights into the e\ufb00ectiveness of these algorithms.\nWe also believe that hybrid\nmethods, combining machine learning and \ufb01rst principles models, will be a fertile ground\nLEARNING FLUID MECHANICS: FROM LIVING ORGANISMS TO MACHINES\nBirds, bats, insects, \ufb01sh, and other aquatic and aerial lifeforms, perform remarkable feats of \ufb02uid manipula-\ntion. They optimize and control their shape and motion to harness unsteady \ufb02uid forces for agile propulsion,\ne\ufb03cient migration, and other maneuvers. The range of \ufb02uid optimization and control observed in biology\nhas inspired humans for millennia. How do these organisms learn to manipulate the \ufb02ow environment?\nTo date, we know of only one species that manipulates \ufb02uids through knowledge of the Navier-Stokes\nequations. Humans have been innovating and engineering devices to harness \ufb02uids since before the dawn\nof recorded history, from dams and irrigation, to mills and sailing. Early e\ufb00orts were achieved through\nintuitive design, although recent quantitative analysis and physics-based design have enabled a revolution\nin performance over the past hundred years. Indeed, physics-based engineering of \ufb02uid systems is a high-\nwater mark of human achievement. However, there are serious challenges associated with equation-based\nanalysis of \ufb02uids, including high-dimensionality and nonlinearity, which defy closed-form solutions and limit\nreal-time optimization and control e\ufb00orts. At the beginning of a new millennium, with increasingly powerful\ntools in machine learning and data-driven optimization, we are again learning how to learn from experience.\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n5\n\n\nSample \nGenerator\nLEARNING \nMACHINE\nSYSTEM\np(x)\nx\n\u0302y\ny\np(y|x)\n\u03c6(x, y, w)\nFigure 3\nThe learning problem: A learning machine uses inputs from a sample generator and observations\nfrom a system to generate an approximation of its output (Credit: Cherkassky & Mulier (2007)).\nSymbols: x \u2014 inputs p(x) \u2014 probability distribution of inputs y \u2014 outputs \u02c6y \u2014 estimated\noutputs, given input x w \u2014 parameters of the learning machine \u03d5(x, y, w) \u2014 structure of the\nlearning machine p(y|x) \u2014 probability of outputs given input x\nfor development.\nThis review is structured as follows: Section 2 outlines the fundamental algorithms of\nmachine learning, followed by their applications to \ufb02ow modeling (Sec. 3), and optimization\nand control (Sec. 4). We provide a summary and outlook of this \ufb01eld in Sec. 5.\n2. MACHINE LEARNING FUNDAMENTALS\nThe learning problem can be formulated as the process of estimating associations be-\ntween inputs, outputs, and parameters of a system using a limited number of observa-\ntions (Cherkassky & Mulier 2007). We distinguish a generator of samples, the system in\nquestion, and a learning machine (LM), as in Fig. 3. We emphasize that the approxima-\ntions by learning machines are fundamentally stochastic and their learning process can be\nsummarized as the minimization of a risk functional:\nR(w) =\nZ\nL(y, \u03c6(x, y, w)) p(x, y) dxdy,\n(1)\nwhere the data x (inputs) and y (outputs) are samples from a probability distribution p,\n\u03c6(x, y, w) de\ufb01nes the structure and w the parameters of the learning machine, and the loss\nfunction L balances the various learning objectives (e.g., accuracy, simplicity, smoothness,\netc.). We emphasize that the risk functional is weighted by a probability distribution p(x, y)\nthat also constrains the predictive capabilities of the learning machine. The various types of\nlearning algorithms can be grouped into three major categories: Supervised, unsupervised\nand semi-supervised, as in Fig. 1. These distinctions signify the degree to which external\nsupervisory information from an expert is available to the learning machine.\nSupervised learning:\nLearning from\nlabeled data by\nproviding corrective\ninformation to the\nalgorithm.\nUnsupervised\nlearning: Learning\npatterns (e.g\nclusters, classes)\nwithout labeled\ntraining data.\nSemi-supervised\nlearning: Learning\nwith partially\nlabeled data (GANs)\nor through receiving\na reward from the\nenvironment\n(Reinforcement\nlearning).\n2.1. Supervised Learning\nSupervised learning implies the availability of corrective information to the learning ma-\nchine. In its simplest and most common form, this implies labeled training data, with labels\ncorresponding to the output of the LM. Minimization of the cost function, which implic-\nitly depends on the training data, will determine the unknown parameters of the LM. In\n6\nBrunton, Noack, and Koumoutsakos\n\n\nxt+1\nht+1\nLSTM\nxt\u22121\nht+1\nLSTM\nxt\nht\u22121\n\u03c3\nht\nht\nct\u22121\nct\n\u2299\n\u03c3\n+\ntanh\n\u2299\ntanh\n\u2299\n\u03c3\nxt+1\nht+1\nRNN\nxt\u22121\nht\u22121\nRNN\nxt\ntanh\nht\u22121\nht\nht\nFigure 4\nRecurrent neural nets (RRNs) for time-series predictions and the Long Short-Term Memory\n(LSTM) regularization (Hochreiter & Schmidhuber (1997)). Symbols: ht\u22121 \u2014 previous cell\noutput ht \u2014 current cell output xt \u2014 input vector ct\u22121 \u2014 previous cell memory ct \u2014 current cell\nmemory \u03c3 \u2014 sigmoid\nthis context, supervised learning dates back to the regression and interpolation methods\nproposed centuries ago by Gauss (Meijering 2002). A commonly employed loss function is\nL(y, \u03c6(x, y, w)) = ||y \u2212\u03c6(x, y, w)||2.\n(2)\nAlternative loss functions may re\ufb02ect di\ufb00erent constraints on the learning machine such\nas sparsity (Hastie et al. 2009; Brunton & Kutz 2019). The choice of the approximation\nfunction re\ufb02ects prior knowledge about the data and the choice between linear and nonlinear\nmethods directly bears on the computational cost associated with the learning methods.\n2.1.1. Neural networks. Neural networks are arguably the most well known methods in\nsupervised learning. They are fundamental nonlinear function approximators, and in recent\nyears a number of e\ufb00orts have been dedicated in understanding their e\ufb00ectiveness. The\nuniversal approximation theorem (Hornik et al. 1989) states that any function may be\napproximated by a su\ufb03ciently large and deep network. Recent work has shown that sparsely\nconnected, deep neural networks are information theoretic optimal nonlinear approximators\nfor a wide range of functions and systems (B\u00a8olcskei et al. 2019).\nNeural network: A\ncomputational\narchitecture, based\nloosely on biological\nnetworks of neurons.\nNeural networks are\noften used for\nnonlinear regression.\nThe power and \ufb02exibility of neural networks emanates from their modular structure\nbased on the neuron as a central building element, a caricature of the neurons in the hu-\nman brain. Each neuron receives an input, processes it through an activation function, and\nproduces an output. Multiple neurons can be combined into di\ufb00erent structures that re\ufb02ect\nknowledge about the problem and the type of data. Feed-forward networks are among the\nmost common structures, and they are composed of layers of neurons, where a weighted out-\nput from one layer is the input to the next layer. NN architectures have an input layer that\nreceives the data and an output layer that produces a prediction. Nonlinear optimization\nmethods, such as back-propagation (Rumelhart et al. 1986), are used to identify the net-\nwork weights to minimize the error between the prediction and labeled training data. Deep\nneural networks involve multiple layers and various types of nonlinear activation functions.\nWhen the activation functions are expressed in terms of convolutional kernels, a powerful\nclass of networks emerges, namely convolutional neural networks (CNN), with great success\nin image and pattern recognition (Krizhevsky et al. 2012; Goodfellow et al. 2016).\nRecurrent neural networks (RNNs), depicted in Fig. 4, are of particular interest to \ufb02uid\nmechanics. They operate on sequences of data (e.g., images from a video, time-series, etc.)\nand their weights are obtained by back-propagation through time (BPTT). RNNs have been\nquite successful for natural language processing and speech recognition. Their architecture\ntakes into account the inherent order of the data, thus augmenting some of the pioneering\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n7\n\n\napplications of classical neural networks on signal processing (Rico-Martinez et al. 1992)\nHowever, the e\ufb00ectiveness of RNNs has been hindered by diminishing or exploding gradients\nthat emerge during their training. The renewed interest in RNNs is largely attributed to\nthe development of the long short-term memory (LSTM) (Hochreiter & Schmidhuber 1997)\nalgorithms that deploy cell states and gating mechanisms to store and forget information\nabout past inputs, thus alleviating the problems with gradients and the transmission of\nlong-term information that standard RNNs su\ufb00er from. An extended architecture, called\nthe multi-dimensional LSTM network (MD-LSTM) (Graves et al. 2007), was proposed to\ne\ufb03ciently handle high-dimensional spatiotemporal data. A number of potent alternatives\nto RNNS have appeared over the years; notably the echo state networks have been used\nwith success to predict certain dynamical systems (Pathak et al. 2018).\n2.1.2. Classi\ufb01cation: Support vector machines and random forests. Classi\ufb01cation is a su-\npervised learning task that can determine the label or category of a set of measurements\nfrom a-priori labeled training data. It is perhaps the oldest method for learning, starting\nwith the perceptron (Rosenblatt 1958), which could classify between two types of linearly\nseparable data.\nTwo fundamental classi\ufb01cation algorithms are support vector machines\n(SVM) (Sch\u00a8olkopf & Smola 2002) and random forests (Breiman 2001), which have been\nwidely adopted in the industry for several learning tasks, until the recent progress by deep\nneural networks. The problem can be speci\ufb01ed by a loss functional, which is most simply\nexpressed for two classes:\nL\n\u0000y, \u03c6(x, y, w)\n\u0001\n=\n(\n0,\nif y = \u03c6(x, y, w),\n1,\nif y \u0338= \u03c6(x, y, w).\n(3)\nHere the output of the learning machine is an indicator on the class to which the data\nbelong. The risk functional quanti\ufb01es the probability of misclassi\ufb01cation and the task is\nto minimize the risk based on the training data by suitable choice of \u03c6(x, y, w). Random\nforests are based on an ensemble of decision trees that hierarchically split the data using\nsimple conditional statements; these decisions are interpretable and fast to evaluate at scale.\nIn the context of classi\ufb01cation, an SVM maps the data into a high-dimensional feature space\non which a linear classi\ufb01cation is possible.\nDeep learning:\nNeural networks\nwith multiple\ninterconnected layers\nthat can create\nhierarchical\nrepresentations of\nthe data.\n2.2. Unsupervised Learning\nThis learning task implies the extraction of features from the data by specifying certain\nglobal criteria and without the need for supervision or a ground-truth label for the results.\nThe types of problems involved here include dimensionality reduction, quantization, and\nclustering. The automated extraction of \ufb02ow features by unsupervised learning algorithms\ncan form the basis of \ufb02ow modeling and control using low-order models.\n2.2.1. Dimensionality reduction I : POD, PCA and auto-encoders. The extraction of \ufb02ow\nfeatures from experimental data and large scale simulations is a cornerstone for \ufb02ow model-\ning. Moreover identifying lower dimensional representations for high-dimensional data can\nbe used as pre-processing for all tasks in supervised learning algorithms. Dimensionality\nreduction can also be viewed as an \u201cinformation \ufb01ltering bottleneck\u201d where the data is\nprocessed through a lower dimensional representation before being mapped backed to the\nambient dimension. The classical proper orthogonal decomposition (POD) algorithm be-\n8\nBrunton, Noack, and Koumoutsakos\n\n\nretain M < D \neigenvectors\n\u00afx = 1\nN\nN\n\u2211\nn = 1\nxn\nS = 1\nN\nN\n\u2211\nn = 1\n(xn \u2212\u00afx)(xn \u2212\u00afx)T\nSui = \u03bbiui\nx\n\u02c6x\nx\n\u02c6x\nz\nz\n\u03d5(x)\n\u03c8(z)\nU\nV\nFigure 5\nPCA/POD (left) vs shallow autoencoder (sAE, middle), versus deep autoencoder (dAE, right). If the node activation\nfunctions in sAE are linear, then U and V are matrices that minimize the loss function \u2225\u02c6x \u2212VUx\u2225. The node activation\nfunctions may be nonlinear, minimizing the loss function \u2225x \u2212\u03c8(\u03d5(x))\u2225. The input x \u2208RD is reduced to z \u2208RM, with\nM \u226aD. Note that the PCA/POD requires the solution of a problem speci\ufb01c eigenvalue equation while the neuron\nmodules and can be extended to nonlinear activation functions and multiple nodes and layers (adapted from Bishop &\nJames (1993)). Symbols: xn \u2014 n-th input vector \u00afx \u2014 mean of input data S \u2014 covariance matrix of mean-subtracted\ndata ui \u2014 eigenvector \u03bbi \u2014 eigenvalue x \u2014 input vector \u02c6x \u2014 autoencoder reconstruction \u03d5(x) \u2014 deep encoder \u03c8(x) \u2014\ndeep decoder U \u2014 linear encoder V \u2014 linear decoder z \u2014 latent variable\nlongs to this category of learning, and will be discussed more in Sec. 3. The POD, or linear\nprincipal components analysis (PCA) as it is more widely known, can be formulated as a\ntwo layer neural network (an autoencoder) with a linear activation function for its linearly\nweighted input, that can be trained by stochastic gradient descent (see Fig. 5). This for-\nmulation is an algorithmic alternative to linear eigenvalue/eigenvector problems in terms\nof neural networks, and it o\ufb00ers a direct route to the nonlinear regime and deep learning\nby adding more layers and a nonlinear activation function on the network. Unsupervised\nlearning algorithms have seen limited use in the \ufb02uid mechanics community, and we believe\nthat this is an opportunity that deserves further exploration. In recent years, the machine\nlearning community has produced numerous auto-encoders that, when properly matched\nwith the possible features of the \ufb02ow \ufb01eld, can lead to signi\ufb01cant insight for reduced-order\nmodeling of stationary and time-dependent data.\nAutoencoder:\nA\nneural network\narchitecture used to\ncompress and\ndecompress\nhigh-dimensional\ndata. They are\npowerful alternatives\nto the Proper\nOrthogonal\nDecomposition\n(POD).\n2.2.2. Dimensionality reduction II: Discrete principal curves and self-organizing maps. The\nmapping between high-dimensional data and a low-dimensional representation can be struc-\ntured through an explicit shaping of the lower dimensional space, possibly re\ufb02ecting an\na-priori knowledge about this subspace. These techniques can be seen as extensions of the\nlinear auto-encoders, where the encoder and decoder can be nonlinear functions. This non-\nlinearity may come however at the expense of losing the inverse relationship between the\nencoder and decoder functions that is one of the strengths of linear PCA. An alternative\nis to de\ufb01ne the decoder as an approximation of the inverse of the encoder, leading to the\nmethod of principal curves. Principal curves are structures on which the data are projected\nduring the encoding step of the learning algorithm. In turn the decoding step amounts to\nan approximation of the inverse of this mapping by adding for example some smoothing\nonto the principal curves. An important version of this process is the self-organizing map\n(SOM) introduced by Kohonen (1995). In SOMs the projection subspace is described into\na \ufb01nite set of values with speci\ufb01ed connectivity architecture and distance metrics.\nThe\nencoder step amounts to identifying for each data point the closest node point on the SOM\nand the decoder step is a weighted regression estimate, using for example kernel functions,\nthat take advantage of the speci\ufb01ed distance metric between the map nodes. This modi\ufb01es\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n9\n\n\nthe node centers, and the process can be iterated until the empirical risk of the autoencoder\nhas been minimized. The SOM capabilities can be exempli\ufb01ed by comparing it to linear\nPCA for two dimensional set of points. The linear PCA will provide as an approximation\nthe least squares straight line between the points whereas the SOM will map the points\nonto a curved line that better approximates the data. We note that SOMs can be extended\nto areas beyond \ufb02oating point data and they o\ufb00er an interesting way for creating data bases\nbased on features of \ufb02ow \ufb01elds.\n2.2.3. Clustering and vector quantization. Clustering is an unsupervised learning technique\nthat identi\ufb01es similar groups in the data. The most common algorithm is k-means cluster-\ning, which partitions data into k clusters; an observation belongs to the cluster with the\nnearest centroid, resulting in a partition of data space into Voronoi cells.\nVector quantizers identify representative points for data that can be partitioned into a\npredetermined number of clusters. These points can then be used instead of the full data\nset so that future samples can be approximated by them. The vector quantizer \u03c6\n\u0000x, w\n\u0001\nprovides a mapping between the data x and the coordinates of the cluster centers. The loss\nfunction is usually the squared distortion of the data from the cluster centers, which must\nbe minimized to identify the parameters of the quantizer:\nL(\u03c6(x, w)) = ||x \u2212\u03c6(x, w)||2.\n(4)\nWe note that vector quantization is a data reduction method, not necessarily employed for\ndimensionality reduction. In the latter the learning problem seeks to identify low dimen-\nsional features in high dimensional data, whereas quantization amounts to \ufb01nding represen-\ntative clusters of the data. Vector quantization must also be distinguished from clustering\nas in the former the number of desired centers is determined a-priori whereas clustering\naims to identify meaningful groupings in the data. When these groupings are represented\nby some prototypes then clustering and quantization have strong similarities.\n2.3. Semi-Supervised Learning\nSemi-supervised learning algorithms operate under partial supervision, either with limited\nlabeled training data, or with other corrective information from the environment.\nTwo\nalgorithms in this category are generative adversarial networks (GAN) and reinforcement\nlearning (RL). In both cases the learning machine is (self-)trained through a game like\nprocess as discussed below.\n2.3.1. Generative adversarial networks (GAN). GANs are learning algorithms that result in\na generative model, i.e. a model that produces data according to a probability distribution,\nwhich mimics that of the data used for its training. The learning machine is composed\nof two networks that compete with each other in a zero sum game (Goodfellow et al.\n2014). The generative network produces candidate data examples that are evaluated by the\ndiscriminative, or critic, network to optimize a certain task. The generative (G) network\u2019s\ntraining objective is to synthesize novel examples of data to fool the discriminative network\ninto misclassifying them as belonging to the true data distribution. The weights of these\nnetworks (N) are obtained through a process, inspired by game theory, called adversarial (A)\nlearning. The \ufb01nal objective of the GAN training process is to identify the generative model\nthat produces an output that re\ufb02ects the underlying system. Labeled data are provided\n10\nBrunton, Noack, and Koumoutsakos\n\n\nby the discriminator network and the function to be minimized is the Kullback-Leibler\ndivergence between the two distributions. In the ensuing \u201cgame\u201d, the discriminator aims\nto maximize the probability of it discriminating between true data and data produced by\nthe generator, while the generator aims to minimize the same probability.\nBecause the\ngenerative and discriminative networks essentially train themselves, after initialization with\nlabeled training data, this procedure is often referred to as self-supervised. This self-training\nprocess adds to the appeal of GANs but at the same time one must be cautious on whether\nan equilibrium will ever be reached in the above mentioned game. As with other training\nalgorithms, large amounts of data help the process but, at the moment, there is no guarantee\nof convergence.\n2.3.2. Reinforcement learning. Reinforcement learning (RL) is a mathematical framework\nfor problem solving (Sutton & Barto 2018) that implies goal-directed interactions of an\nagent with its environment.\nIn RL the agent has a repertoire of actions and perceives\nstates. Unlike in supervised learning, the agent does not have labeled information about\nthe correct actions, but instead learns from its own experiences, in the form of rewards\nthat may be infrequent and partial; thus, this is referred to as semi-supervised learning.\nMoreover, the agent is not concerned only with uncovering patterns in its actions or in the\nenvironment, but also with maximizing its long term rewards. Reinforcement learning is\nclosely linked to dynamic programming (Bellman 1952) as it also models interactions with\nthe environment as a Markov decision process.\nUnlike dynamic programming, RL does\nnot require a model of the dynamics, such as a Markov transition model, but proceeds by\nrepeated interaction with the environment through trial-and-error. We believe that it is\nprecisely this approximation that makes it highly suitable for complex problems in \ufb02uid\ndynamics. The two central elements of RL are the agent\u2019s policy, a mapping a = \u03c0(s)\nbetween the state s of the system and the optimal action a, and the value function V (s)\nthat represents the utility of reaching the state s for maximizing the agent\u2019s long-term\nrewards.\nGames are one of the key applications of RL that exemplify its strengths and limitations.\nOne of the early successes of RL is the backgammon learner of Tesauro (1992). The program\nstarted out from scratch as a novice player, trained by playing a couple of million times\nagainst itself, won the computer backgammon olympiad, and eventually became comparable\nto the three best human players in the world. In recent years, advances in high-performance\ncomputing and deep neural-network architectures have produced agents that are capable\nof performing at or above human performance at video games and strategy games that\nare much more complicated than backgammon, such as Go (Mnih et al. 2015) and the AI\ngym (Mnih et al. 2015; Silver et al. 2016). It is important to emphasize that RL requires\nsigni\ufb01cant computational resources due to the large numbers of episodes required to properly\naccount for the interaction of the agent and the environment. This cost may be trivial for\ngames but it may be prohibitive in experiments and \ufb02ow simulations, a situation that is\nrapidly changing (Verma et al. 2018).\nA core challenge for RL is the long-term credit assignment (LTCA) problem, especially\nwhen rewards are sparse or very delayed in time (for example consider the case of a perching\nbird or robot).\nLTCA implies inference, from a long sequence of states and actions, of\ncausal relations between individual decisions and rewards.\nA number of e\ufb00orts address\nthese issues by augmenting an originally sparsely-rewarded objective with densely-rewarded\nsubgoals (Schaul et al. 2015). A related issue is the proper accounting of past experiences\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n11\n\n\nby the agent as it actively forms a new policy Novati et al. (2019).\n2.4. Stochastic Optimization: A Learning Algorithms Perspective\nOptimization is an inherent part of learning, as a risk functional is minimized in order\nto identify the parameters of the learning machine.\nThere is, however, one more link\nthat we wish to highlight in this review: optimization (and search) algorithms can be\ncast in the context of learning algorithms and more speci\ufb01cally as the process of learning\nthe probability distribution of the design points that maximize a certain objective. This\nconnection was pioneered by Rechenberg (1973); Schwefel (1977), who introduced Evolution\nStrategies (ES) and adapted the variance of their search space based on the success rate\nof their experiments. This process is also reminiscent of the operations of selection and\nmutation that are key ingredients of Genetic Algorithms (GA) (Holland 1975) and Genetic\nProgramming (Koza 1992). ES and GAs algorithms can be considered as hybrids between\ngradient search strategies, which may e\ufb00ectively march downhill towards a minimum, and\nLatin-Hypercube or Monte-Carlo sampling methods, which maximally explore the search\nspace. Genetic programming was developed in the late 1980s by J. R. Koza, a PhD student\nof John Holland.\nGenetic programming generalized parameter optimization to function\noptimization, initially coded as a tree of operations (Koza 1992). A critical aspect of these\nalgorithms is that they rely on an iterative construction of the probability distribution,\nbased on data values of the objective function. This iterative construction can be lenhthy\nand practically impossible for problems with expensive objective function evaluations.\nOver the past twenty years, ES and GAs have begun to converge into the framework of\nestimation of distribution algorithms (EDAs). The CMA-ES algorithm (Ostermeier et al.\n1994; Hansen et al. 2003) is a prominent example of evolution strategies using an adaptive\nestimation of the covariance matrix of a Gaussian probability distribution, to guide the\nsearch for optimal parameters. This covariance matrix is adapted iteratively using the best\npoints in each iteration. The CMA-ES is closely related to a number of other algorithms\nincluding the mixed Bayesian optimization algorithms (MBOAs) (Pelikan et al. 2004), and\nthe reader is referred to Kern et al. (2004) for a comparative review.\nIn recent years,\nthis line of work has evolved into the more generalized information-geometric optimization\n(IGO) framework (Ollivier et al. 2017). IGO algorithms allow for families of probability\ndistributions whose parameters are learned during the optimization process and maintain\nthe cost function invariance as a major design principle. The resulting algorithm makes\nno assumption on the objective function to be optimized and its \ufb02ow is equivalent to a\nstochastic gradient descent. These techniques have been proven to be e\ufb00ective on a number\nof simpli\ufb01ed benchmark problems; however, their scaling remains unclear and there are\nfew guarantees for convergence in cost function landscapes such as those encountered in\ncomplex \ufb02uid dynamics problems. We note also that there is interest in deploying these\nmethods in order to minimize the cost functions associated with classical machine learning\ntasks (Salimans et al. 2017).\n2.5. Important Topics We Have Not Covered: Bayesian Inference, Gaussian\nProcesses\nThere are a number of learning algorithms that this review does not address, but which\ndemand particular attention from the \ufb02uid mechanics community. First and foremost we\nwish to mention Bayesian inference, which aims to inform the model structure and its pa-\n12\nBrunton, Noack, and Koumoutsakos\n\n\nrameters from data in a probabilistic framework. Bayesian inference is fundamental for\nuncertainty quanti\ufb01cation, and it is also fundamentally a learning method, as data are\nused to adapt the model estimates. An alternative view casts machine learning algorithms\nin a Bayesian framework (Theodoridis 2015; Barber 2012).\nThe above mentioned opti-\nmization algorithms provide also a link between these two views. Whereas optimization\nalgorithms aim to provide the best parameters of a model for given data in a stochastic\nmanner, Bayesian inference aims to provide the full probability distribution of the model\nparameters. It may be argued that Bayesian inference is an even more powerful language\nthan machine learning, as it provides probability distributions for all parameters, leading to\nrobust predictions, rather than single values, as is usually the case with classical machine\nlearning algorithms. However, a key drawback for Bayesian inference is its computational\ncost, as it involves sampling and integration in high-dimensional spaces, which can be pro-\nhibitive for expensive function evaluations (e.g.\nwind tunnel experiments or large scale\nDNS). Along the same lines one must mention Gaussian processes (GaP), which resemble\nkernel-based methods for regression. However, GaPs develop these kernels adaptively based\non the available data. They also provide probability distributions for the respective model\nparameters. GaPs have been used extensively in problems related to time-dependent prob-\nlems and they may be considered competitors, albeit more costly, to RNNs and echo state\nnetworks. Finally, we note the use of GaPs as surrogates for expensive cost\n3. FLOW MODELING WITH MACHINE LEARNING\nFirst principles, such as conservation laws, have been the dominant building blocks for \ufb02ow\nmodeling over the past centuries. However, for high Reynolds numbers, scale resolving sim-\nulations using the most prominent model in \ufb02uid mechanics, the Navier-Stokes equations,\nis beyond our current computational resources. An alternative is to perform simulations\nbased on approximations of these equations or laboratory experiments for a speci\ufb01c con\ufb01gu-\nration. However, simulations and experiments are expensive for iterative optimization, and\nsimulations are often too slow for real-time control (Brunton & Noack 2015). Consequently,\nconsiderable e\ufb00ort has been placed on obtaining accurate and e\ufb03cient reduced-order mod-\nels that capture essential \ufb02ow mechanisms at a fraction of the cost (Rowley & Dawson\n2016). Machine learning presents new avenues for dimensionality reduction and reduced\norder modeling in \ufb02uid mechanics by providing a concise framework that complements and\nextends existing methodologies.\nReduced-order\nModel (ROM):\nRepresentation of a\nhigh-dimensional\nsystem in terms of a\nlow-dimensional one,\nbalancing accuracy\nand e\ufb03ciency.\nWe distinguish two complementary directions: dimensionality reduction and reduced-\norder modeling. Dimensionality reduction involves extracting key features and dominant\npatterns that may be used as reduced coordinates where the \ufb02uid is compactly and e\ufb03-\nciently described (Taira et al. 2017). Reduced-order modeling describes the spatiotemporal\nevolution of the \ufb02ow as a parametrized dynamical system, although it may also involve\ndeveloping a statistical map from parameters to averaged quantities, such as drag.\nThere have been signi\ufb01cant e\ufb00orts to identify coordinate transformations and reductions\nthat simplify dynamics and capture essential \ufb02ow physics: the proper orthogonal decom-\nposition (POD) is a notable example (Lumley 1970). Model reduction, such as Galerkin\nprojection of the Navier-Stokes equations onto an orthogonal basis of POD modes, bene\ufb01ts\nfrom a close connection to the governing equations; however, it is intrusive, requiring hu-\nman expertise to develop models from a working simulation. Machine learning constitutes\na rapidly growing body of modular algorithms for data-driven system identi\ufb01cation and\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n13\n\n\nmodeling. Unique aspects of data-driven modeling of \ufb02uid \ufb02ows include the availability of\npartial prior knowledge of the governing equations, constraints, and symmetries. With ad-\nvances in simulation capabilities and experimental techniques, \ufb02uid dynamics is becoming\na data rich \ufb01eld, thus amenable to a wealth of machine learning algorithms.\nIn this review, we distinguish machine learning algorithms to model \ufb02ow 1) kinematics\nthrough the extraction \ufb02ow features and 2) dynamics through the adoption of various\nlearning architectures.\n3.1. Flow Feature Extraction\nPattern recognition and data mining are core strengths of machine learning with many\ntechniques that are readily applicable to spatiotemporal \ufb02ow data. We distinguish linear\nand nonlinear dimensionality reduction techniques, followed by clustering and classi\ufb01cation.\nWe also consider accelerated measurement and computation strategies, as well as methods\nto process experimental \ufb02ow \ufb01eld data.\n3.1.1. Dimensionality reduction: Linear and nonlinear embeddings. A common approach\nin \ufb02uid dynamics simulation and modeling is to de\ufb01ne an orthogonal linear transformation\nfrom physical coordinates into a modal basis. The POD provides such an orthogonal basis\nfor complex geometries based on empirical measurements. Sirovich (1987) introduced the\nsnapshot POD, which reduces the computation to a simple data-driven procedure involving\na singular value decomposition.\nInterestingly, in the same year, Sirovich used POD to\ngenerate a low-dimensional feature space for the classi\ufb01cation of human faces, which is a\nfoundation for much of modern computer vision (Sirovich & Kirby 1987).\nPOD is closely related to the algorithm of principal component analysis (PCA), one\nof the fundamental algorithms of applied statistics and machine learning, to describe cor-\nrelations in high-dimensional data.\nWe recall that the PCA can be expressed as a two\nlayer neural network, called an autoencoder, to compress high-dimensional data for a com-\npact representation as shown in Fig. 5. This network embeds high-dimensional data into a\nlow-dimensional latent space, and then decodes from the latent space back to the original\nhigh-dimensional space. When the network nodes are linear and the encoder and decoder\nare constrained to be transposes of one another, the autoencoder is closely related to the\nstandard POD/PCA decomposition ( (Baldi & Hornik 1989), please see also Fig. 6). How-\never, the structure of the neural network autoencoder is modular, and by using nonlinear\nactivation units for the nodes, it is possible to develop nonlinear embeddings, potentially\nproviding more compact coordinates. This observation led to the development of one of\nthe \ufb01rst applications of deep neural networks to reconstruct the near wall velocity \ufb01eld\nin a turbulent channel \ufb02ow using wall pressure and shear (Milano & Koumoutsakos 2002).\nMore powerful autoencoders are today available in the ML community and this link deserves\nfurther exploration.\nOn the basis of the universal approximation theorem (Hornik et al. 1989), stating that a\nsu\ufb03ciently large neural network can represent an arbitrarily complex input\u2013output function,\ndeep neural networks are increasingly used to obtain more e\ufb00ective nonlinear coordinates\nfor complex \ufb02ows. However, deep learning often implies the availability of large volumes\nof training data that far exceed the parameters of the network. The resulting models are\nusually good for interpolation but may not be suitable for extrapolation when the new input\ndata have di\ufb00erent probability distributions than the training data (see Eq. (1)). In many\n14\nBrunton, Noack, and Koumoutsakos\n\n\nFlow snapshots\nPOD modes\nAutoencoder modes\nFigure 6\nUnsupervised learning example: Merging of two vortices (top), POD modes (middle) and\nrespective modes from a linear auto-encoder (bottom). Note that unlike POD modes, the\nautoencoder modes are not orthogonal.\nmodern machine learning applications, such as image classi\ufb01cation, the training data are\nso vast that it is natural to expect that most future classi\ufb01cation tasks will fall within an\ninterpolation of the training data. For example, the ImageNet data set in 2012 (Krizhevsky\net al. 2012) contained over 15 million labeled images, which sparked the current movement\nin deep learning (LeCun et al. 2015). Despite the abundance of data from experiments and\nsimulations the \ufb02uid mechanics community is still distanced from this working paradigm.\nHowever, it may be possible in the coming years to curate large, labeled and complete\nenough \ufb02uid databases to facilitate the deployment of such deep learning algorithms.\n3.1.2. Clustering and classi\ufb01cation. Clustering and classi\ufb01cation are cornerstones of ma-\nchine learning. There are dozens of mature algorithms to choose from, depending on the\nsize of the data and the desired number of categories. The k-means algorithm has been\nsuccessfully employed by Kaiser et al. (2014) to develop a data-driven discretization of a\nhigh-dimensional phase space for the \ufb02uid mixing layer. This low-dimensional representa-\ntion, in terms of a small number of clusters, enabled tractable Markov transition models\nfor how the \ufb02ow evolves in time from one state to another. Because the cluster centroids\nexist in the data space, it is possible to associate each cluster centroid with a physical \ufb02ow\n\ufb01eld, lending additional interpretability. In Amsallem et al. (2012) k-means clustering was\nused to partition phase space into separate regions, in which local reduced-order bases were\nconstructed, resulting in improved stability and robustness to parameter variations.\nClassi\ufb01cation is also widely used in \ufb02uid dynamics to distinguish between various canon-\nical behaviors and dynamic regimes. Classi\ufb01cation is a supervised learning approach where\nlabeled data is used to develop a model to sort new data into one of several categories.\nRecently, Colvert et al. (2018) investigated the classi\ufb01cation of wake topology (e.g., 2S,\n2P+2S, 2P+4S) behind a pitching airfoil from local vorticity measurements using neural\nnetworks; extensions have compared performance for various types of sensors (Alsalman\net al. 2018). In Wang & Hemati (2017) the k nearest neighbors (KNN) algorithm was used\nto detect exotic wakes. Similarly, neural networks have been combined with dynamical sys-\ntems models to detect \ufb02ow disturbances and estimate their parameters (Hou et al. 2019).\nRelated graph and network approaches in \ufb02uids by Nair & Taira (2015) have been used\nfor community detection in wake \ufb02ows (Meena et al. 2018). Finally, one of the earliest\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n15\n\n\nexamples of machine learning classi\ufb01cation in \ufb02uid dynamics by Bright et al. (2013) was\nbased on sparse representation (Wright et al. 2009).\n3.1.3. Sparse and randomized methods. In parallel to machine learning, there have been\ngreat strides in sparse optimization and randomized linear algebra. Machine learning and\nsparse algorithms are synergistic, in that underlying low-dimensional representations facili-\ntate sparse measurements (Manohar et al. 2018) and fast randomized computations (Halko\net al. 2011). Decreasing the amount of data to train and execute a model is important\nwhen a fast decision is required, as in control. In this context algorithms for the e\ufb03cient\nacquisition and reconstruction of sparse signals, such as compressed sensing Donoho (2006),\nhave already been leveraged for compact representations of wall-bounded turbulence (Bour-\nguignon et al. 2014) and for POD based \ufb02ow reconstruction (Bai et al. 2014).\nLow-dimensional structure in data also facilitates dramatically accelerated computations\nvia randomized linear algebra (Mahoney 2011; Halko et al. 2011). If a matrix has low-rank\nstructure, then there are extremely e\ufb03cient matrix decomposition algorithms based on\nrandom sampling; this is closely related to the idea of sparsity and the high-dimensional\ngeometry of sparse vectors. The basic idea is that if a large matrix has low-dimensional\nstructure, then with high probability this structure will be preserved after projecting the\ncolumns or rows onto a random low-dimensional subspace, facilitating e\ufb03cient downstream\ncomputations. These so-called randomized numerical methods have the potential to trans-\nform computational linear algebra, providing accurate matrix decompositions at a fraction\nof the cost of deterministic methods.\nFor example, randomized linear algebra may be\nused to e\ufb03ciently compute the singular value decomposition, which is used to compute\nPCA (Rokhlin et al. 2009; Halko et al. 2011).\n3.1.4. Super resolution and \ufb02ow cleansing. Much of machine learning is focused on imaging\nscience, providing robust approaches to improve resolution and remove noise and corruption\nbased on statistical inference. These super resolution and de-noising algorithms have the\npotential to improve the quality of both simulations and experiments in \ufb02uids.\nSuper resolution involves the inference of a high-resolution image from low-resolution\nmeasurements, leveraging the statistical structure of high-resolution training data. Several\napproaches have been developed for super resolution, for example based on a library of\nexamples (Freeman et al. 2002), sparse representation in a library (Yang et al. 2010), and\nmost recently based on convolutional neural networks (Dong et al. 2014). Experimental \ufb02ow\n\ufb01eld measurements from particle image velocimetry (PIV) (Willert & Gharib 1991; Adrian\n1991) provide a compelling application where there is a tension between local \ufb02ow resolution\nand the size of the imaging domain. Super resolution could leverage expensive and high-\nresolution data on smaller domains to improve the resolution on a larger imaging domain.\nLarge eddy simulations (LES) (Germano et al. 1991; Meneveau & Katz 2000) may also\nbene\ufb01t from super resolution to infer the high-resolution structure inside a low-resolution\ncell that is required to compute boundary conditions. Recently Fukami et al. (2018) have\ndeveloped a CNN-based super-resolution algorithm and demonstrated its e\ufb00ectiveness on\nturbulent \ufb02ow reconstruction, showing that the energy spectrum is accurately preserved.\nOne drawback of super-resolution is that it is often extremely costly computationally, mak-\ning it useful for applications where high-resolution imaging may be prohibitively expensive;\nhowever, improved neural-network based approaches may drive the cost down signi\ufb01cantly.\nWe note also that Xie et al. (2018) recently employed GANs for super-resolution.\n16\nBrunton, Noack, and Koumoutsakos\n\n\nThe processing of experimental PIV and particle tracking has been also one of the \ufb01rst\napplications of machine learning. Neural networks have been used for fast PIV (Knaak et al.\n1997) and particle tracking velocimetry (Labont\u00b4e 1999), with impressive demonstrations for\nthree-dimensional Lagrangian particle tracking (Ouellette et al. 2006). More recently, deep\nconvolutional neural networks have been used to construct velocity \ufb01elds from PIV image\npairs (Lee et al. 2017). Related approaches have also been used to detect spurious vectors\nin PIV data (Liang et al. 2003) to remove outliers and \ufb01ll in corrupt pixels.\n3.2. Modeling Flow Dynamics\nA central goal of modeling is to balance e\ufb03ciency and accuracy. When modeling physical\nsystems, interpretability and generalizability are also critical considerations.\n3.2.1. Linear models through nonlinear embeddings: DMD and Koopman analysis. Many\nclassical techniques in system identi\ufb01cation may be considered machine learning, as they\nare data-driven models that generalize beyond the training data. The dynamic mode de-\ncomposition (DMD) (Schmid 2010; Kutz et al. 2016) is a modern approach, to extract\nspatiotemporal coherent structures from time-series data of \ufb02uid \ufb02ows, resulting in a low-\ndimensional linear model for the evolution of these dominant coherent structures. DMD is\nbased on data-driven regression and is equally valid for time-resolved experimental and nu-\nmerical data. DMD is closely related to the Koopman operator (Rowley et al. 2009; Mezic\n2013), which is an in\ufb01nite dimensional linear operator that describes how all measurement\nfunctions of the system evolve in time. Because the DMD algorithm is based on linear \ufb02ow\n\ufb01eld measurements (i.e., direct measurements of the \ufb02uid velocity or vorticity \ufb01eld), the\nresulting models may not be able to capture nonlinear transients.\nRecently, there has been a concerted e\ufb00ort to identify nonlinear measurements that\nevolve linearly in time, establishing a coordinate system where the nonlinear dynamics\nappear linear.\nThe extended DMD (Williams et al. 2015) and variational approach of\nconformation dynamics (VAC) (No\u00b4e & Nuske 2013; N\u00a8uske et al. 2016) enrich the model with\nnonlinear measurements, leveraging kernel methods (Williams et al. 2015) and dictionary\nlearning (Li et al. 2017). These special nonlinear measurements are generally challenging\nto represent, and deep learning architectures are now used to identify nonlinear Koopman\ncoordinate systems where the dynamics appear linear (Wehmeyer & No\u00b4e 2018; Mardt et al.\n2018; Takeishi et al. 2017; Lusch et al. 2018). The VAMPnet architecture (Wehmeyer &\nNo\u00b4e 2018; Mardt et al. 2018) uses a time-lagged auto-encoder and a custom variational\nscore to identify Koopman coordinates on an impressive protein folding example. Based\non the performance of VAMPnet, \ufb02uid dynamics may bene\ufb01t from neighboring \ufb01elds, such\nas molecular dynamics, which have similar modeling issues, including stochasticity, coarse-\ngrained dynamics, and massive separation of time scales.\n3.2.2. Neural network modeling. Over the last three decades neural networks have been\nused to model dynamical systems and \ufb02uid mechanics problems. Early examples include\nthe use of NNs to learn the solutions of ordinary and partial di\ufb00erential equations (Dis-\nsanayake & Phan-Thien 1994; Gonzalez-Garcia et al. 1998; Lagaris et al. 1998). We note\nthat the potential of this work has not been fully explored and in recent years there is\nfurther advances (Chen et al. 2018; Raissi & Karniadakis 2018) including discrete and con-\ntinuous in time networks. We note also the possibility of using these methods to uncover\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n17\n\n\nlatent variables and reduce the number of parametric studies often associated with partial\ndi\ufb00erential equations Raissi et al. (2019). Neural networks are also frequently employed\nin nonlinear system identi\ufb01cation techniques, such as NARMAX, which are often used to\nmodel \ufb02uid systems (Glaz et al. 2010). In \ufb02uid mechanics, neural networks were widely\nused to model heat transfer (Jambunathan et al. 1996), turbomachinery (Pierret & Van den\nBraembussche 1998), turbulent \ufb02ows (Milano & Koumoutsakos 2002), and other problems\nin aeronautics (Faller & Schreck 1996).\nRecurrent Neural Netwosk with LSTMs (Hochreiter & Schmidhuber (1997) have been\nrevolutionary for speech recognition, and they are considered one of the landmark successes\nof arti\ufb01cial intellignece.\nThe are currently being used to model dynamical systems and\nfor data driven predictions of extreme events (Wan et al. 2018; Vlachas et al. 2018). An\ninteresting \ufb01nding of these studies is that combining data driven and reduced order mod-\nels is a potent method that outperforms each of its components on a number of studies.\nGenerative adversarial networks (GANs) (Goodfellow et al. 2014) are also being used to\ninfer dynamical systems from data (Wu et al. 2018). GANs have potential to aid in the\nmodeling and simulation of turbulence (Kim et al. 2018), although this \ufb01eld is nascent, yet\nwell worthy of exploration.\nDespite the promise and widespread use of neural networks in dynamical systems, a\nnumber of challenges remains. Neural networks are fundamentally interpolative, and so the\nfunction is only well approximated in the span (or under the probability distribution) of\nthe sampled data used to train them. Thus, caution should be exercised when using neural\nnetwork models for an extrapolation task. In many computer vision and speech recognition\nexamples, the training data are so vast that nearly all future tasks may be viewed as an\ninterpolation on the training data. However, this scale of training has not been achieve\nto date in \ufb02uid mechanics. Similarly, neural network models are prone to over\ufb01tting, and\ncare must be taken to cross-validate models on a su\ufb03ciently chosen test set; best practices\nare discussed in Goodfellow et al. (2016). Finally, it is important to explicitly incorporate\nphysical properties such as symmetries, constraints, and conserved quantities.\n3.2.3. Parsimonious nonlinear models. Parsimony is a recurring theme in mathematical\nphysics, from Hamilton\u2019s principle of least action to the apparent simplicity of many gov-\nerning equations. In contrast to the raw representational power of neural networks, machine\nlearning algorithms are also being employed to identify minimal models that balance predic-\ntive accuracy with model complexity, preventing over\ufb01tting and promoting interpretability\nand generalizability. Genetic programming has been used to discover conservation laws and\ngoverning equations (Schmidt & Lipson 2009). Sparse regression in a library of candidate\nmodels has also been proposed to identify dynamical systems (Brunton et al. 2016) and\npartial di\ufb00erential equations (Rudy et al. 2017; Schae\ufb00er 2017). Loiseau & Brunton (2018)\nidenti\ufb01ed sparse reduced-order models of several \ufb02ow systems, enforcing energy conservation\nas a constraint. In both genetic programming and sparse identi\ufb01cation, a Pareto analysis\nis used to identify models that have the best tradeo\ufb00between model complexity, measured\nin number of terms, and predictive accuracy. In cases where the physics is known, this\napproach typically discovers the correct governing equations, providing exceptional gener-\nalizability compared with other leading algorithms in machine learning.\n3.2.4. Closure models with machine learning. The use of machine learning to develop tur-\nbulence closures is an active area of research (Duraisamy et al. 2019). The extremely wide\n18\nBrunton, Noack, and Koumoutsakos\n\n\nFigure 7\nComparison of standard neural network architecture (a) with modi\ufb01ed neural network for\nidentifying Galilean invariant Reynolds stress models (b), reproduced from Ling et al. (2016b)\nwith permission from The Journal of Fluid Mechanics. Symbols: \u03bb1, \u00b7 \u00b7 \u00b7 , \u03bb5: \ufb01ve tensor\ninvariants T (n): isotropic basis tensors g(n): scalar coe\ufb03cients weighing the basis tensors b:\nanisotropy tensor\nrange of spatiotemporal scales in turbulent \ufb02ows makes it exceedingly costly to resolve all\nscales in simulation, and even with Moore\u2019s law, we are likely several decades away from re-\nsolving all scales in con\ufb01gurations of industrial interest (e.g., aircraft turbines, submarines,\netc.). It is common to truncate small scales and model their e\ufb00ect on the large scales with a\nclosure model. Common approaches include Reynolds averaged Navier Stokes (RANS) and\nlarge eddy simulation (LES). However, these models may require careful tuning to match\nfully resolved simulations or experiments.\nMachine learning has been used to identify and model discrepancies in the Reynolds\nstress tensor between a RANS model and high-\ufb01delity simulations (Ling & Templeton\n2015; Parish & Duraisamy 2016; Ling et al. 2016b; Xiao et al. 2016; Singh et al. 2017; Wang\net al. 2017). Ling & Templeton (2015) compare support vector machines, Adaboost decision\ntrees, and random forests to classify and predict regions of high uncertainty in the Reynolds\nstress tensor. Wang et al. (2017) use random forests to built a supervised model for the\ndiscrepancy in the Reynolds stress tensor. Xiao et al. (2016) leveraged sparse online velocity\nmeasurements in a Bayesian framework to infer these discrepancies. In related work, Parish\n& Duraisamy (2016) develop the \ufb01eld inversion and machine learning modeling framework,\nthat builds corrective models based on inverse modeling. This framework was later used by\nSingh et al. (2017) to develop a neural network enhanced correction to the Spalart-Allmaras\nRANS model, with excellent performance. A key result by Ling et al. (2016b) employed the\n\ufb01rst deep network architecture with many hidden layers to model the anisotropic Reynolds\nstress tensor, as shown in Fig. 7. Their novel architecture incorporates a multiplicative layer\nto embed Galilean invariance into the tensor predictions. This provides an innovative and\nsimple approach to embed known physical symmetries and invariances into the learning\narchitecture (Ling et al. 2016a), which we believe will be essential in future e\ufb00orts that\ncombine learning for physics. For large eddy simulation closures, Maulik et al. (2019) have\nemployed arti\ufb01cial neural networks to predict the turbulence source term from coarsely\nresolved quantities.\n3.2.5. Challenges of machine learning for dynamical systems. Applying machine learning to\nmodel physical dynamical systems poses a number of unique challenges and opportunities.\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n19\n\n\nModel interpretability and generalizability are essential cornerstones in physics.\nA well\ncrafted model will yield hypotheses for new phenomena that have not been observed before.\nThis principle is clearly exhibited in the parsimonious formulation of classical mechanics in\nNewton\u2019s second law.\nHigh-dimensional systems, such as those encountered in unsteady \ufb02uid dynamics, have\nthe challenges of multi-scale dynamics, sensitivity to noise and disturbances, latent variables\nand transients, all of which require careful attention when applying machine learning tech-\nniques. In machine learning for dynamics, we distinguish two tasks: discovering unknown\nphysics and improving models by incorporating known physics. Many learning architec-\ntures, cannot readily incorporate physical constraints in the form of symmetries, boundary\nconditions, and global conservation laws. This is a critical area for continued development\nand a number of recent works have presented generalizable physics models (Battaglia et al.\n2018).\n4. FLOW OPTIMIZATION AND CONTROL USING MACHINE LEARNING\nLearning algorithms are well suited to \ufb02ow optimization and control problems involving\n\u201cblack-box\u201d or multimodal cost functions. These algorithms are iterative and often require\nseveral orders of magnitude more cost function evaluations than gradient based algorithms\n(Bewley et al. 2001). Moreover they do not o\ufb00er guarantees of convergence and we suggest\nthat they are avoided when techniques such as adjoint methods are applicable.\nAt the\nsame time, techniques such as reinforcement learning have been shown to outperform even\noptimal \ufb02ow control strategies (Novati et al. 2019). Indeed there are several classes of \ufb02ow\ncontrol and optimization problems where learning algorithms may be the method of choice\nas described below.\nIn contrast to \ufb02ow modeling, learning algorithms for optimization and control interact\nwith the data sampling process in several ways. First, in line with the modeling e\ufb00orts\ndescribed in earlier sections, machine learning can be applied to develop explicit surrogate\nmodels that relate the cost function and the control/optimization parameters. Surrogate\nmodels such as neural networks can then be amenable even to gradient based methods,\nalthough they often get stuck in local minima. Multi-\ufb01delity algorithms (Perdikaris et al.\n2016) can also be employed to combine surrogates with the cost function of the complete\nproblem. As the learning progresses, new data are requested as guided by the results of\nthe optimization. Alternatively, the optimization or control problem may be described in\nterms of learning probability distributions of parameters that minimize the cost function.\nThese probability distributions are constructed from cost function samples obtained during\nthe optimization process. Furthermore, the high-dimensional and non-convex optimization\nprocedures that are currently employed to train nonlinear learning machines are well-suited\nto the high-dimensional, nonlinear optimization problems in \ufb02ow control.\nWe remark that the lines between optimization and control are becoming blurred by the\navailability of powerful computers (see focus box). However, the range of critical spatiotem-\nporal scales and the non-linearity of the underlying processes will likely render real-time\noptimization for \ufb02ow control a challenge for decades to come.\n20\nBrunton, Noack, and Koumoutsakos\n\n\n4.1. Stochastic Flow Optimization: Learning Probability Distributions\nStochastic optimization includes evolutionary strategies and genetic algorithms, which were\noriginally developed based on bio-inspired principles. However, over the last 20 years these\nalgorithms have been placed in a learning framework (Kern et al. 2004).\nStochastic optimization has found widespread use in engineering design, in particular as\nmany engineering problems involve \u201cblack-box\u201d type of cost functions. A much abbreviated\nlist of applications include aerodynamic shape optimization (Giannakoglou et al. 2006),\nuninhabited aerial vehicles (UAVs) (Hamdaoui et al. 2010), shape and motion optimization\nin arti\ufb01cial swimmers (Gazzola et al. 2012; Van Rees et al. 2015), and improved power\nextraction in cross\ufb02ow turbines (Strom et al. 2017).\nWe refer to the review article by\nSkinner & Zare-Behtash (2018) for an extensive comparison of gradient-based and stochastic\noptimization algorithms for aerodynamics.\nThese algorithm involve large numbers of iterations, and they can bene\ufb01t from mas-\nsively parallel computer architectures. Advances in automation have also facilitated their\napplication in experimental (Strom et al. 2017; Martin & Gharib 2018) and industrial set-\ntings (Bueche et al. 2002). We note that stochastic optimization algorithms are well-suited\nto address the experimental and industrial challenges associated with uncertainty, such as\nunexpected system behavior, partial descriptions of the system and its environment, and\nexogenous disturbances. Hansen et al. (2009) proposed an approach to enhance the capa-\nbilities of evolutionary algorithms for online optimization of a combustor test-rig.\nStochastic \ufb02ow optimization will continue to bene\ufb01t from advances in computer hard-\nware and experimental techniques. At the same time, convergence proofs, explainability,\nand reliability are outstanding issues that need to be taken into consideration when de-\nploying such algorithms in \ufb02uid mechanics problems. Hybrid algorithms, combining in a\nproblem speci\ufb01c manner stochastic techniques and gradient-based methods may o\ufb00er the\nbest strategy for \ufb02ow control problems.\nOPTIMIZATION AND CONTROL: BOUNDARIES ERASED BY FAST COMPUTERS\nOptimization and control are intimately related, and the boundaries are becoming even less distinct with\nincreasingly fast computers, as summarized in Tsiotras & Mesbahi (2017) (page 195):\n\u201cInterestingly,\nthe distinction between optimization and control is largely semantic and (alas!)\nimplementation-dependent. If one has the capability of solving optimization problems fast enough on the\n\ufb02y to close the loop, then one has (in principle) a feedback control law... Not surprisingly then, the same\nalgorithm can be viewed as solving an optimization or a control problem, based solely on the capabilities of the\navailable hardware. With the continued advent of faster and more capable computer hardware architectures,\nthe boundary between optimization and control will become even more blurred. However, when optimization\nis embedded in the implementation of feedback control, the classical problems of control such as robustness\nto model uncertainty, time delays, and process and measurement noise become of paramount importance,\nparticularly for high-performance aerospace systems.\u201d\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n21\n\n\n4.2. Flow Control with Machine Learning\nFeedback \ufb02ow control modi\ufb01es the behavior of a \ufb02uid dynamic system through actuation\nthat is informed by sensor measurements. Feedback is necessary to stabilize an unstable\nsystem, attenuate sensor noise, and compensate for external disturbances and model un-\ncertainty. Challenges of \ufb02ow control include a high-dimensional state, nonlinearity, latent\nvariables, and time delays.\nMachine learning algorithms have been used extensively in\ncontrol, system identi\ufb01cation, and sensor placement.\n4.2.1. Neural networks for control. Neural networks have received signi\ufb01cant attention for\nsystem identi\ufb01cation (see Sec. 3) and control, including applications in aerodynamics (Phan\net al. 1995).\nThe application of NNs to turbulence \ufb02ow control was pioneered in Lee\net al. (1997).\nThe skin-friction drag of a turbulent boundary layer was reduced using\nlocal wall-normal blowing and suction based on few skin friction sensors. A sensor-based\ncontrol law was learned from a known optimal full-information controller, with little loss\nin overall performance. Furthermore, a single-layer network was optimized for skin-friction\ndrag reduction without incorporating any prior knowledge of the actuation commands.\nBoth strategies led to a conceptually simple local opposition control. Several other studies\nemploy neural networks, e.g. for phasor control (Rabault et al. 2019) or even frequency cross\ntalk. The price for the theoretical advantage of approximating arbitrary nonlinear control\nlaws is the need for many parameters to be optimized. Neural network control may require\nexorbitant computational or experimental resources for con\ufb01gurations with complex high-\ndimensional nonlinearities and many sensors and actuators. At the same time, the training\ntime of neural networks has been improved by several orders of magnitude since these early\napplications, which warrants further investigation into their potential for \ufb02ow control.\n4.2.2. Genetic algorithms for control. Genetic algorithms have been deployed to solve a\nnumber of \ufb02ow control problems.\nThey require that the structure of the control law is\npre-speci\ufb01ed and contains only a few adjustable parameters. An example of GA for con-\ntrol design in \ufb02uids was used for experimental mixing optimization of the backward-facing\nstep (Benard et al. 2016). As with neural network control, the learning time increases with\nthe number of parameters, making it challenging or even prohibitive for controllers with\nnonlinearities, e.g. a constant-linear-quadratic law, with signal history, e.g. a Kalman \ufb01lter,\nor with multiple sensors and actuators.\nGenetic programming has been used extensively in active control for engineering ap-\nplications (Dracopoulos 1997; Fleming & Purshouse 2002) and in recent years in several\n\ufb02ow control plants.\nThis includes the learning of multi-frequency open-loop actuation,\nmulti-input sensor feedback, and distributed control. We refer to Duriez et al. (2016) for\nan in-depth description of the method and to Noack (2018) for an overview of the plants.\nWe remark that most control laws have been obtained within 1000 test evalutations, each\nrequiring only few seconds in a wind-tunnel.\n4.3. Flow Control via Reinforcement Learning\nIn recent years RL has advanced beyond the realm of games and has become a fundamental\nmode of problem solving in a growing number of domains, including to reproduce the dy-\nnamics of hydrological systems (Loucks et al. 2005), actively control the oscillatory laminar\n\ufb02ow around blu\ufb00bodies (Gu\u00b4eniat et al. 2016), study the individual (Gazzola et al. 2014)\n22\nBrunton, Noack, and Koumoutsakos\n\n\nFigure 8\nDeep reinforcement learning schematic (left), and application to the study of the collective motion of \ufb01sh via the\nNavier-Stokes equations (right; Verma et al. (2018)).Symbols: St:state, \u03c0w:policy, W:parameters, m(St), \u03c3(St):mean,\nstandard deviation for action\nor the collective motion of \ufb01sh (Gazzola et al. 2016; Novati et al. 2017; Verma et al. 2018),\nmaximize the range of simulated (Reddy et al. 2016) and robotic (Reddy et al. 2018) gliders,\noptimize the kinematic motion of UAVs (Kim et al. 2004; Tedrake et al. 2009), and optimize\nthe motion of microswimmers (Colabrese et al. 2017, 2018). Figure 8 provides a schematic of\nreinforcement learning with an examples showcasing its application to collective swimming\nas resolved by the Navier-Stokes equations.\nReinforcement\nLearning: An agent\nlearns a policy of\nactions that\nmaximize its long\nterm rewards by\ninteracting with its\nenvironment.\nFluid mechanics knowledge is essential for applications of RL, as success or failure hinges\non properly selecting states, actions, and rewards that re\ufb02ect the governing mechanisms of\nthe \ufb02ow problem. Natural organisms and their sensors, such as the visual system in a bird\nor the lateral line in a \ufb01sh, can guide the choice of states. As sensor technologies progress at\na rapid pace, the algorithmic challenge may be that of optimal sensor placement (Papadim-\nitriou & Papadimitriou 2015; Manohar et al. 2018). The actions re\ufb02ect the \ufb02ow actuation\ndevice and may involve body deformation or wing \ufb02apping. Rewards may include energetic\nfactors, such as the cost of transport, or proximity to the center of a \ufb01sh school to avoid pre-\ndation. The computational cost of RL remains a challenge to its widespread adoption, but\nwe believe this de\ufb01ciency can be mediated by the parallelism inherent to RL. There is grow-\ning interest in methods designed to be transferable from low-accuracy (e.g. 2-dimensional)\nto high-accuracy (e.g. 3-dimensional) simulations (Verma et al. 2018), or from simulations\nto related real-world applications (Richter et al. 2016).\n5. DISCUSSION AND OUTLOOK\nThis review presents machine learning algorithms that could augment existing e\ufb00orts for\nthe study, modeling and control of \ufb02uid mechanics. The interface of the two \ufb01elds has a long\nhistory and has attracted a renewed interest in the last few years. The review addresses\napplications of machine learning in problems of \ufb02ow modeling, optimization, and control\nin experiments and simulations. It highlights some successes of machine learning in critical\n\ufb02uid mechanics tasks, such as dimensionality reduction, feature extraction, PIV processing,\nsuper-resolution, reduced-order modeling, turbulence closure, shape optimization, and \ufb02ow\ncontrol. It discusses lessons learned from these e\ufb00orts and justify the current interest in\nlight of the technological advances of our times. Machine learning comprises data-driven\noptimization and applied regression techniques that are well-suited for high-dimensional,\nnonlinear problems, such as those encountered in \ufb02uid dynamics; \ufb02uid mechanics expertise\nwill be necessary to formulate these optimization and regression problems.\nMachine learning algorithms present an arsenal of tools, largely unexplored in \ufb02uid\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n23\n\n\nmechanics research, that can augment existing modes of inquiry. Fluid mechanics knowledge\nand centuries old principles such as conservation laws remain relevant in the era of big data.\nSuch knowledge can help frame more precise questions and assist in reducing the large\ncomputational cost often associated with the application of machine learning algorithms\nin \ufb02ow control and optimization. The exploration and visualization of high-dimensional\nsearch spaces will be dramatically simpli\ufb01ed by machine learning and increasingly capable\nhigh-performance computing resources.\nIn the near future, experience with machine learning algorithms will help frame new\nquestions in \ufb02uid mechanics, extending decades old linearized models and linear approaches\nto the nonlinear regime. The transition to the nonlinear realm of machine learning is facil-\nitated by the abundance of open source software and methods, and the prevalent openness\nof the ML community. In the long term machine learning will undoubtedly o\ufb00er a fresh\nlook into old problems of \ufb02uid mechanics under the light of data. Interpreting the machine\nlearning solutions, and re\ufb01ning the problem statement, will again require \ufb02uid mechanics\nexpertise.\nA word of caution is necessary to balance the current excitement about data-driven\nresearch and the (almost magical) powers of machine learning. After all a machine learn-\ning algorithm will always provide some kind of answer to any question, that is based on\nits training data; data that may not be even relevant to the question at hand. Properly\nformulating the question, selecting the data as well as the learning machine and its training\nis a process where all parts are critical.\nApplying machine learning algorithms to \ufb02uid\nmecahnics is faced with numerous outstanding challenges (and opportunities!). Although\nmany \ufb01elds of machine learning are concerned with raw predictive performance, applica-\ntions in \ufb02uid mechanics often require models that are explainable, generalizable, and have\nguarantees.\nAlthough deep learning will undoubtedly become a critical tool in several aspects of \ufb02ow\nmodeling, not all machine learning is deep learning. It is important to consider several fac-\ntors when choosing methods, including the quality and quantity of data, the desired inputs\nand outputs, the cost function to be optimized, whether or not the task involves interpola-\ntion or extrapolation, and how important it is for models to be explainable. It is important\nto cross-validate machine learned models, otherwise results may be prone to over\ufb01tting.\nIt is also important to develop and adapt machine learning algorithms that are not only\nphysics informed but also physics consistent, a major outstanding challenge in arti\ufb01cial in-\ntelligence. This review concludes with a call for action in the \ufb02uid mechanics community to\nfurther embrace open and reproducible research products and standards. Reproducibility is\na cornerstone of science and a number of frameworks are currently developed to render this\nintop a systematic scientifc process (Barber (2015)). It is increasingly possible to document\nprocedures, archive code, and host data so that others can reproduce results. Data is essen-\ntial for machine learning; thus, creating and curating benchmark datasets and software will\nspur interest among researchers in related \ufb01elds, driving progress. These \ufb02uid benchmarks\nare more challenging than the \u201ctraditional\u201d image data sets encountered in machine learn-\ning: \ufb02uids data is multi-modal and multi-\ufb01delity; it has high-resolution in some dimensions\nand is sparse in others; many tasks balance multiple objectives; and foremost, our data\ncomes from a dynamical system, where many tasks do not admit post-mortem analysis.\nWe are entering a new era in \ufb02uid mechanics research. Centuries of theoretical devel-\nopments based on \ufb01rst principles are merging with data-driven analysis. This fusion could\nprovide solutions to many long-sought problems in \ufb02uid dynamics and o\ufb00ers new hope for\n24\nBrunton, Noack, and Koumoutsakos\n\n\nenhanced understanding of turbulence and its governing mechanisms.\nReproducibility: The\nprocess of\ndocumenting\nprocedures,\narchiving code and\ndata so that\nscienti\ufb01c results can\nbe readily\nreproducible.\nSUMMARY POINTS\n1. Machine learning entails powerful information processing algorithms that are rele-\nvant for modeling, optimization, and control of \ufb02uid \ufb02ows. E\ufb00ective problem solvers\nwill have expertise in machine learning and in-depth knowledge of \ufb02uid mechanics.\n2. Fluid mechanics has been traditionally concerned with big data. For decades it has\nused machine learning to understand, predict, optimize, and control \ufb02ows. Cur-\nrently, machine learning capabilities are advancing at an unprecedented rate, and\n\ufb02uid mechanics is beginning to tap into the full potential of these powerful methods.\n3. Many tasks in \ufb02uid mechanics, such as reduced-order modeling, shape optimization,\nand feedback control, may be posed as optimization and regression tasks. Machine\nlearning can dramatically improve optimization performance and reduce conver-\ngence time. Machine learning is also used for dimensionality reduction, identifying\nlow-dimensional manifolds and discrete \ufb02ow regimes, which bene\ufb01t understanding.\n4. Flow control strategies have been traditionally based on the precise sequence: start\nwith understanding, follow with modeling and then control. The machine-learning\nparadigm suggests more \ufb02exibility in this sequence and iterations between data\ndriven and \ufb01rst principle approaches.\nFUTURE ISSUES\n1. Machine learning algorithms often come without guarantees for performance, ro-\nbustness, or convergence, even for well-de\ufb01ned tasks.\nHow can interpretability,\ngeneralizability, and explainability of the results be achieved?\n2. Incorporating and enforcing known \ufb02ow physics is a challenge and opportunity for\nmachine learning algorithms.\nCan we hybridize e\ufb00ectively data driven and \ufb01rst\nprinciple approaches in \ufb02uid mechanics?\n3. There are many possibilities to discover new physical mechanisms, symmetries,\nconstraints, and invariances from \ufb02uid mechanics data.\n4. Data driven modeling can be a potent alternative in revisiting existing empirical\nlaws in \ufb02uid mechanics.\n5. Machine learning encourages open sharing of data and software. Can this assist the\ndevelopment of frameworks for reproducible and open science in \ufb02uid mechanics?\n6. Fluids researchers will bene\ufb01t from interfacing with the machine learning commu-\nnity, where the latest advances are reported in peer reviewed conferences.\nDISCLOSURE STATEMENT\nThe authors are not aware of any a\ufb03liations, memberships, funding, or \ufb01nancial holdings\nthat might be perceived as a\ufb00ecting the objectivity of this review.\nACKNOWLEDGMENTS\nSLB acknowledges funding from the Army Research O\ufb03ce (ARO W911NF-17-1-0306,\nW911NF-17-1-0422) and the Air Force O\ufb03ce of Scienti\ufb01c Research (AFOSR FA9550-18-\n1-0200). BRN acknowledges funding by LIMSI-CNRS, Universit\u00b4e Paris Sud (SMEMaG),\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n25\n\n\nthe French National Research Agency (ANR-11-IDEX-0003-02, ANR-17-ASTR-0022) and\nthe German Research Foundation (CRC880, SE 2504/2-1, SE 2504/3-1). PK acknowledges\nfunding from the ERC Advanced Investigator Award (FMCoBe, No.\n34117), the Swiss\nNational Science Foundation and the Swiss Supercomputing center (CSCS). We are grate-\nful for discussions with Nathan Kutz (University of Washington), Jean-Christophe Loiseau\n(ENSAM ParisTech, Paris), Fran\u00b8cois Lusseyran (LIMSI-CNRS, Paris), Guido Novati (ETH\nZurich), Luc Pastur (ENSTA ParisTech, Paris), and Pantelis Vlachas (ETH Zurich).\nLITERATURE CITED\nAdrian RJ. 1991. Particle-imaging techniques for experimental \ufb02uid mechanics. Annu. Rev. Fluid\nMech. 23:261\u2013304\nAlsalman M, Colvert B, Kanso E. 2018. Training bioinspired sensors to classify \ufb02ows. Bioinspiration\nBiomim. 14:016009\nAmsallem D, Zahr MJ, Farhat C. 2012. Nonlinear model order reduction based on local reduced-\norder bases. Int. J. Numer. Meth. Engin. 92:891\u2013916\nAndrychowicz M, Wolski F, Ray A, Schneider J, Fong R, et al. 2017. Hindsight experience replay,\nIn Adv. Neural Inf. Process. Syst.\nBai Z, Wimalajeewa T, Berger Z, Wang G, Glauser M, Varshney PK. 2014. Low-dimensional ap-\nproach for reconstruction of airfoil data via compressive sensing. AIAA J. 53:920\u2013933\nHow linear PCA\n(or POD) connects\nto linear neural\nnetworks.\nBaldi P, Hornik K. 1989. Neural networks and principal component analysis: Learning\nfrom examples without local minima. Neural Netw. 2:53\u201358\nBarber D. 2012. Bayesian inference and machine learning. Cambridge University Press\nReproducible\nscience: a\nframework.\nBarber, R. F. and Candes E. J., 2015. Controlling the false discovery rate via knock-\no\ufb00s. Annals of Statistics 43:2055-2085\nBattaglia PW, Hamrick JB, Bapst V, Sanchez-Gonzalez A, Zambaldi V, et al. 2018. Relational\ninductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261\nBellman R. 1952. On the theory of dynamic programming. Proc. Natl. Acad. Sci. USA 38:716\u2013719\nBenard N, Pons-Prats J, Periaux J, Bugeda G, Braud P, et al. 2016. Turbulent separated shear \ufb02ow\ncontrol by surface plasma actuator: experimental optimization by genetic algorithm approach.\nExp. Fluids 57:22:1\u201317\nBewley TR, Moin P, Temam R. 2001. DNS-based predictive control of turbulence: an optimal\nbenchmark for feedback algorithms. J. Fluid Mech. 447:179\u2013225\nBishop CM, James GD. 1993. Analysis of multiphase \ufb02ows using dual-energy gamma densitometry\nand neural networks. Nucl. Instrum. Methods Phys. Res. 327:580\u2013593\nTheoretical\nAnalysis of the\napproximation\nproperties of deep\nneural networks.\nB\u00a8olcskei H, Grohs P, Kutyniok G, Petersen P. 2019. Optimal approximation with\nsparsely connected deep neural networks. SIAM J. Math. Data Sci. 1:8\u201345\nBourguignon JL, Tropp JA, Sharma AS, McKeon BJ. 2014. Compact representation of wall-bounded\nturbulence using compressive sampling. Phys. Fluids 26:015109\nBousmalis K, Irpan A, Wohlhart P, Bai Y, Kelcey M, et al. 2017. Using simulation and domain\nadaptation to improve e\ufb03ciency of deep robotic grasping. arXiv preprint arXiv:1709.07857\nBreiman L. 2001. Random forests. Mach. Learn. 45:5\u201332\nBright I, Lin G, Kutz JN. 2013. Compressive sensing and machine learning strategies for character-\nizing the \ufb02ow around a cylinder with limited pressure measurements. Phys. Fluids 25:1\u201315\nBrunton SL, Kutz JN. 2019. Data-driven science and engineering: Machine learning, dynamical\nsystems, and control. Cambridge University Press\nBrunton SL, Noack BR. 2015. Closed-loop turbulence control: Progress and challenges. Appl. Mech.\nRev. 67:1\u201348\nBrunton SL, Proctor JL, Kutz JN. 2016. Discovering governing equations from data by sparse\nidenti\ufb01cation of nonlinear dynamical systems. Proc. Natl. Acad. Sci. USA 113:3932\u20133937\nBueche D, Stoll P, Dornberger R, Koumoutsakos P. 2002. Multi-objective evolutionary algorithm for\nthe optimization of noisy combustion problems. IEEE Trans. Syst. Man. Cybern. C 32:460\u2013473\n26\nBrunton, Noack, and Koumoutsakos\n\n\nChen TQ, Rubanova Y, Bettencourt J, Duvenaud DK. 2018. Neural ordinary di\ufb00erential equa-\ntions. In Advances in Neural Information Processing Systems 31, eds. S Bengio, H Wallach,\nH Larochelle, K Grauman, N Cesa-Bianchi, R Garnett. Curran Associates, Inc., 6571\u20136583\nCherkassky V, Mulier FM. 2007. Learning from data: concepts, theory, and methods. John Wiley\n& Sons\nColabrese S, Gustavsson K, Celani A, Biferale L. 2017. Flow navigation by smart microswimmers\nvia reinforcement learning. Phys. Rev. Lett. 118:158004\nColabrese S, Gustavsson K, Celani A, Biferale L. 2018. Smart inertial particles. Phys. Rev. Fluids\n3:084301\nColvert B, Alsalman M, Kanso E. 2018. Classifying vortex wakes using neural networks. Bioinspi-\nration Biomim. 13:025003\nDissanayake M, Phan-Thien N. 1994. Neural-network-based approximations for solving partial dif-\nferential equations. Comm. Numer. Meth. Eng. 10:195\u2013201\nDong C, Loy CC, He K, Tang X. 2014. Learning a deep convolutional network for image super-\nresolution, In Comput. Vis. ECCV. Springer\nDonoho, D.L., 2006. Compressed Sensing, In IEEE Transactions on Information Theory. 52:1289-\n1306\nDracopoulos DC. 1997. Evolutionary learning algorithms for neural adaptive control. Perspectives\nin Neural Computing. London, etc.: Springer-Verlag\nDuraisamy K, Iaccarino G, Xiao H. 2019. Turbulence modeling in the age of data. Annu. Rev. Fluid\nMech. 51:357\u2013377\nDuriez T, Brunton SL, Noack BR. 2016. Machine learning control: Taming nonlinear dynamics and\nturbulence. Springer\nFaller WE, Schreck SJ. 1996. Neural networks: applications and opportunities in aeronautics. Prog.\nAerosp. Sci. 32:433\u2013456\nFleming PJ, Purshouse RC. 2002. Evolutionary algorithms in control systems engineering: a survey.\nControl Eng. Pract. 10:1223\u20131241\nFreeman WT, Jones TR, Pasztor EC. 2002. Example-based super-resolution. IEEE Comput. Graph.\n22:56\u201365\nFukami K, Fukagata K, Taira K. 2018. Super-resolution reconstruction of turbulent \ufb02ows with\nmachine learning. arXiv preprint arXiv:1811.11328\nGardner E. 1988. The space of interactions in neural network models. J. Phys. A 21:257\nGazzola M, Hejazialhosseini B, Koumoutsakos P. 2014. Reinforcement learning and wavelet adapted\nvortex methods for simulations of self-propelled swimmers. SIAM J. Sci. Comp. 36:B622\u2013B639\nGazzola M, Tchieu A, Alexeev D, De Brauer A, Koumoutsakos P. 2016. Learning to school in the\npresence of hydrodynamic interactions. J. Fluid Mech. 789\nGazzola M, Van Rees WM, Koumoutsakos P. 2012. C-start: optimal start of larval \ufb01sh. J. Fluid\nMech. 698:5\u201318\nGermano M, Piomelli U, Moin P, Cabot WH. 1991. A dynamic subgrid-scale eddy viscosity model.\nPhys. Fluids 3:1760\u20131765\nGiannakoglou K, Papadimitriou D, Kampolis I. 2006. Aerodynamic shape design using evolutionary\nalgorithms and new gradient-assisted metamodels. Comput. Methods Appl. Mech. Eng. 195:6312\u2013\n6329\nGlaz B, Liu L, Friedmann PP. 2010. Reduced-order nonlinear unsteady aerodynamic modeling using\na surrogate-based recurrence framework. AIAA J. 48:2418\u20132429\nGonzalez-Garcia R, Rico-Martinez R, Kevrekidis I. 1998. Identi\ufb01cation of distributed parameter\nsystems: A neural net based approach. Comput. Chem. Eng. 22:S965\u2013S968\nGoodfellow I, Bengio Y, Courville A. 2016. Deep learning. MIT Press\nPowerful deep\nlearning\narchitecture that\nlearns through a\ngame between a\nnetwork that can\n\u201cgenerate\u201d new\ndata and a network\nthat is an expert\nclassi\ufb01er.\nGoodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, et al. 2014. Gener-\native adversarial nets, In Adv. Neural Inf. Process. Syst.\nGrant I, Pan X. 1995. An investigation of the performance of multi layer, neural networks applied\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n27\n\n\nto the analysis of PIV images. Exp. Fluids 19:159\u2013166\nGraves A, Fern\u00b4andez S, Schmidhuber J. 2007. Multi-dimensional recurrent neural networks. Arti\ufb01-\ncial Neural Networks\u2013ICANN :549\u2014-558\nGu\u00b4eniat F, Mathelin L, Hussaini MY. 2016. A statistical learning strategy for closed-loop control\nof \ufb02uid \ufb02ows. Theor. Comp. Fluid Dyn. 30:497\u2013510\nHalko N, Martinsson PG, Tropp JA. 2011. Finding structure with randomness: Probabilistic algo-\nrithms for constructing approximate matrix decompositions. SIAM Rev. 53:217\u2013288\nHamdaoui M, Chaskalovic J, Doncieux S, Sagaut P. 2010. Using multiobjective evolutionary algo-\nrithms and data-mining methods to optimize ornithopters\u2019 kinematics. J. Aircraft 47:1504\nHansen N, M\u00a8uller SD, Koumoutsakos P. 2003. Reducing the time complexity of the derandomized\nevolution strategy with covariance matrix adaptation (CMA-ES). Evol. Comput. 11:1\u201318\nHansen N, Niederberger AS, Guzzella L, Koumoutsakos P. 2009. A method for handling uncertainty\nin evolutionary optimization with an application to feedback control of combustion. IEEE Trans.\nEvol. Comput. 13:180\u2013197\nHastie T, Tibshirani R, Friedman J, Hastie T, Friedman J, Tibshirani R. 2009. The elements of\nstatistical learning, vol. 2. Springer\nHinton GE, Sejnowski TJ. 1986. Learning and releaming in Boltzmann machines, In Parallel Dis-\ntributed Processing: Explorations in the Microstructure of Cognition, vol. 1. MIT Press\nRegularization of\nrecurrent neural\nnetworks, and\nmajor contributor\nto the success of\nGoogle translate.\nHochreiter S, Schmidhuber J. 1997. Long short-term memory. Neural Comput. 9:1735\u2013\n1780\nHolland JH. 1975. Adaptation in natural and arti\ufb01cial systems: An introductory analysis with\napplications to biology, control, and arti\ufb01cial intelligence. University of Michigan Press\nHop\ufb01eld JJ. 1982. Neural networks and physical systems with emergent collective computational\nabilities. Proc. Natl. Acad. Sci. USA 79:2554\u20132558\nHornik K, Stinchcombe M, White H. 1989. Multilayer feedforward networks are universal approxi-\nmators. Neural Netw. 2:359\u2013366\nHou W, Darakananda D, Eldredge J. 2019. Machine learning based detection of \ufb02ow disturbances\nusing surface pressure measurements, In AIAA Scitech\nJambunathan K, Hartle S, Ashforth-Frost S, Fontama V. 1996. Evaluating convective heat transfer\ncoe\ufb03cients using neural networks. Int. J. Heat Mass Transf. 39:2329\u20132332\nKaiser E, Noack BR, Cordier L, Spohn A, Segond M, et al. 2014. Cluster-based reduced-order\nmodelling of a mixing layer. J. Fluid Mech. 754:365\u2013414\nKern S, M\u00a8uller SD, Hansen N, B\u00a8uche D, Ocenasek J, Koumoutsakos P. 2004. Learning Probability\nDistributions in Continuous Evolutionary Algorithms \u2013 A Comparative Review. Nat. Comput.\n3:77\u2013112\nKim B, Azevedo VC, Thuerey N, Kim T, Gross M, Solenthaler B. 2018. Deep \ufb02uids: A generative\nnetwork for parameterized \ufb02uid simulations. arXiv preprint arXiv:1806.02071\nKim HJ, Jordan MI, Sastry S, Ng AY. 2004. Autonomous helicopter \ufb02ight via reinforcement learning,\nIn Adv. Neural Inf. Process. Syst.\nKnaak M, Rothlubbers C, Orglmeister R. 1997. A Hop\ufb01eld neural network for \ufb02ow \ufb01eld computation\nbased on particle image velocimetry/particle tracking velocimetry image sequences. IEEE Int.\nConf. Neural Netw. 1:48\u201352\nKohonen T. 1995. Self-organizing maps. Springer Verlag\nKolmogorov A. 1941. The local structure of turbulence in incompressible viscous \ufb02uid for very large\nReynolds number. Dokl. Akad. Nauk SSSR 30:9\u201313. (translated and reprinted 1991 in Proc. R.\nSoc. Lond. A 434, 9\u201313)\nKoza JR. 1992. Genetic Programming: On the Programming of Computers by Means of Natural\nSelection. Boston: The MIT Press\nKrizhevsky A, Sutskever I, Hinton GE. 2012. Imagenet classi\ufb01cation with deep convolutional neural\nnetworks, In Adv. Neural Inf. Process. Syst.\nKutz JN, Brunton SL, Brunton BW, Proctor JL. 2016. Dynamic mode decomposition: Data-driven\n28\nBrunton, Noack, and Koumoutsakos\n\n\nmodeling of complex systems. SIAM\nLabont\u00b4e G. 1999. A new neural network for particle-tracking velocimetry. Exp. Fluids 26:340\u2013346\nLagaris IE, Likas A, Fotiadis DI. 1998. Arti\ufb01cial neural networks for solving ordinary and partial\ndi\ufb00erential equations. IEEE Trans. Neural Netw. 9:987\u20131000\nLeCun Y, Bengio Y, Hinton G. 2015. Deep learning. Nature 521:436\u2013444\nLee C, Kim J, Babcock D, Goodman R. 1997. Application of neural networks to turbulence control\nfor drag reduction. Phys. Fluids 9:1740\u20131747\nLee Y, Yang H, Yin Z. 2017. PIV-DCNN: cascaded deep convolutional neural networks for particle\nimage velocimetry. Exp. Fluids 58:171\nLi Q, Dietrich F, Bollt EM, Kevrekidis IG. 2017. Extended dynamic mode decomposition with\ndictionary learning: A data-driven adaptive spectral decomposition of the Koopman operator.\nChaos 27:103111\nLiang D, Jiang C, Li Y. 2003. Cellular neural network to detect spurious vectors in PIV data. Exp.\nFluids 34:52\u201362\nLing J, Jones R, Templeton J. 2016a. Machine learning strategies for systems with invariance\nproperties. J. Comp. Phys. 318:22\u201335\nLing J, Kurzawski A, Templeton J. 2016b. Reynolds averaged turbulence modelling using deep\nneural networks with embedded invariance. J. Fluid Mech. 807:155\u2013166\nLing J, Templeton J. 2015. Evaluation of machine learning algorithms for prediction of regions of\nhigh Reynolds averaged Navier Stokes uncertainty. Phys. Fluids 27:085103\nLoiseau JC, Brunton SL. 2018. Constrained sparse Galerkin regression. J. Fluid Mech. 838:42\u201367\nLoucks D, van Beek E, Stedinger J, Dijkman J, Villars M. 2005. Water resources systems planning\nand management: An introduction to methods, vol. 2. Springer International Publishing\nLumley J. 1970. Stochastic tools in turbulence. New York: Academic Press\nLusch B, Kutz JN, Brunton SL. 2018. Deep learning for universal linear embeddings of nonlinear\ndynamics. Nat. Commun. 9:4950\nMahoney MW. 2011. Randomized algorithms for matrices and data. Foundations and Trends in\nMachine Learning 3:123\u2013224\nManohar K, Brunton BW, Kutz JN, Brunton SL. 2018. Data-driven sparse sensor placement. IEEE\nControl Syst. Mag. 38:63\u201386\nMardt A, Pasquali L, Wu H, No\u00b4e F. 2018. VAMPnets: Deep learning of molecular kinetics. Nat.\nCommun. 9\nMartin N, Gharib M. 2018. Experimental trajectory optimization of a \ufb02apping \ufb01n propulsor using\nan evolutionary strategy. Bioinspiration Biomim. 14:016010\nMaulik R, San O, Rasheed A, Vedula P. 2019. Subgrid modelling for two-dimensional turbulence\nusing neural networks. J. Fluid Mech. 858:122\u2013144\nMeena MG, Nair AG, Taira K. 2018. Network community-based model reduction for vortical \ufb02ows.\nPhys. Rev. E 97:063103\nMehta UB, Kutler P. 1984. Computational aerodynamics and arti\ufb01cial intelligence. Technical Mem-\norandum 85994, NASA\nMeijering E. 2002. A chronology of interpolation: from ancient astronomy to modern signal and\nimage processing. Proc. IEEE 90:319\u2013342\nMeneveau C, Katz J. 2000. Scale-invariance and turbulence models for large-eddy simulation. Annu.\nRev. Fluid Mech. 32:1\u201332\nMezic I. 2013. Analysis of \ufb02uid \ufb02ows via spectral properties of the Koopman operator. Annu. Rev.\nFluid Mech. 45:357\u2013378\nMilano M, Koumoutsakos P. 2002. Neural network modeling for near wall turbulent \ufb02ow. J. Comp.\nPhys. 182:1\u201326\nMinsky M, Papert SA. 1969. Perceptrons: An introduction to computational geometry. MIT Press\nMnih V, Kavukcuoglu K, Silver D, Rusu Aa, Veness J, et al. 2015. Human-level control through\ndeep reinforcement learning. Nature 518:529\u2013533\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n29\n\n\nNair AG, Taira K. 2015. Network-theoretic approach to sparsi\ufb01ed discrete vortex dynamics. J. Fluid\nMech. 768:549\u2013571\nNoack BR. 2018. Closed-loop turbulence control\u2014From human to machine learning (and retour),\nIn Proc. FSSIC, eds. Y Zhou, M Kimura, G Peng, AD Lucey, L Hung. Springer\nNo\u00b4e F, Nuske F. 2013. A variational approach to modeling slow processes in stochastic dynamical\nsystems. SIAM Multiscale Model Simul. 11:635\u2013655\nNovati G, Mahadevan L, Koumoutsakos P. 2019. Controlled gliding and perching through deep\nreinforcement learning. Physical Review Fluids\nNovati G, Verma S, Alexeev D, Rossinelli D, Van Rees WM, Koumoutsakos P. 2017. Synchronisation\nthrough learning for two self-propelled swimmers. Bioinspiration Biomim. 12:aa6311\nN\u00a8uske F, Schneider R, Vitalini F, No\u00b4e F. 2016. Variational tensor approach for approximating the\nrare-event kinetics of macromolecular systems. J. Chem. Phys. 144:054105\nOllivier Y, Arnold L, Auger A, Hansen N. 2017. Information-geometric optimization algorithms: A\nunifying picture via invariance principles. J. Mach. Learn. Res. 18:564\u2013628\nOstermeier A, Gawelczyk A, Hansen N. 1994. Step-size adaptation based on non-local use of selection\ninformation. Internat. Conf. PPSN\nOuellette NT, Xu H, Bodenschatz E. 2006. A quantitative study of three-dimensional Lagrangian\nparticle tracking algorithms. Exp. Fluids 40:301\u2013313\nPapadimitriou DI, Papadimitriou C. 2015. Optimal Sensor Placement for the Estimation of Turbu-\nlent Model Parameters in CFD. Int. J. Uncert. Quant. 5:545\u2013568\nParish EJ, Duraisamy K. 2016. A paradigm for data-driven predictive modeling using \ufb01eld inversion\nand machine learning. J. Comp. Phys. 305:758\u2013774\nPathak J, Hunt B, Girvan M, Lu Z, Ott E. 2018. Model-free prediction of large spatiotemporally\nchaotic systems from data: a reservoir computing approach. Phys. Rev. Lett. 120:024102\nPelikan M, Ocenasek J, Trebst S, Troyer M, Alet F. 2004. Computational complexity and simulation\nof rare events of ising spin glasses. Genetic and Evolutionary Computation\u2013GECCO :36\u201347\nPerdikaris P, Venturi D, Karniadakis G. 2016. Multi\ufb01delity information fusion algorithms for high-\ndimensional systems and massive data sets. SIAM J. Sci. Comput. 38:B521\u2013B538\nPerlman E, Burns R, Li Y, Meneveau C. 2007. Data exploration of turbulence simulations using a\ndatabase cluster, In ACM/IEEE Conf. Supercomp.\nPhan MQ, Juang JN, Hyland DC. 1995. On neural networks in identi\ufb01cation and control of dynamic\nsystems, In Wave Motion, Intelligent Structures And Nonlinear Mechanics\nPierret S, Van den Braembussche R. 1998. Turbomachinery blade design using a Navier-Stokes\nsolver and arti\ufb01cial neural network. ASME Intern. Gas Turb. Aeroeng. Cong. Exh.\nPollard A, Castillo L, Danaila L, Glauser M. 2016. Whither turbulence and big data in the 21st\ncentury? Springer\nRabault J, Kuchta M, Jensen A, R\u00b4eglade U, Cerardi N. 2019. Arti\ufb01cial neural networks trained\nthrough deep reinforcement learning discover control strategies for active \ufb02ow control. J. Fluid\nMech. 865:281\u2013302\nRaissi M, Karniadakis GE. 2018. Hidden physics models: Machine learning of nonlinear partial\ndi\ufb00erential equations. J. Comp. Phys. 357:125\u2013141\nRaissi M, Perdikaris P, Karniadakis G. 2019. Physics-informed neural networks: A deep learn-\ning framework for solving forward and inverse problems involving nonlinear partial di\ufb00erential\nequations. J. Comp. Phys. 378:686\u2013707\nRechenberg I. 1964. Kybernetische l\u00a8osungsansteuerung einer experimentellen forschungsaufgabe, In\nAnn. Conf. WGLR Berlin, vol. 35\nRechenberg I. 1973. Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der\nbiologischen Evolution. Stuttgart: Frommann-Holzboog\nReddy G, Celani A, Sejnowski TJ, Vergassola M. 2016. Learning to soar in turbulent environments.\nProc. Natl. Acad. Sci. USA 113:E4877\u2013E4884\nReddy G, Wong-Ng J, Celani A, Sejnowski TJ, Vergassola M. 2018. Glider soaring via reinforcement\n30\nBrunton, Noack, and Koumoutsakos\n\n\nlearning in the \ufb01eld. Nature 562:236\u2013239\nRichter SR, Vineet V, Roth S, Koltun V. 2016. Playing for data: Ground truth from computer\ngames, In Comput. Vis. ECCV. Springer\nRico-Martinez R., Krischer K., Kevrekidis I.G., Kube M.C., Hudson J.L., 1992. Discrete-vs.\ncontinuous-time nonlinear signal processing of Cu electrodissolution data Chem. Eng. Commun\n118:25-48\nRokhlin V, Szlam A, Tygert M. 2009. A randomized algorithm for principal component analysis.\nSIAM J. Matrix Anal. Appl. 31:1100\u20131124\nFirst example of a\nsimple binary\nnetwork with\nlearning\ncapabilities\nRosenblatt F. 1958. The perceptron: a probabilistic model for information storage and\norganization in the brain. Psychol. Rev. 65:386\nRowley CW, Dawson S. 2016. Model reduction for \ufb02ow analysis and control. Annu. Rev. Fluid\nMech. 49\nRowley CW, Mezi\u00b4c I, Bagheri S, Schlatter P, Henningson D. 2009. Spectral analysis of nonlinear\n\ufb02ows. J. Fluid Mech. 645:115\u2013127\nRudy SH, Brunton SL, Proctor JL, Kutz JN. 2017. Data-driven discovery of partial di\ufb00erential\nequations. Sci. Adv. 3\nRumelhart DE, Hinton GE, Williams RJ, et al. 1986. Learning representations by back-propagating\nerrors. Nature 323:533\u2013536\nSalimans T, Ho J, Chen X, Sutskever I. 2017. Evolution strategies as a scalable alternative to\nreinforcement learning. arXiv preprint arXiv:1703.03864\nSchae\ufb00er H. 2017. Learning partial di\ufb00erential equations via data discovery and sparse optimization,\nIn Proc. R. Soc. A, vol. 473. The Royal Society\nSchaul T, Horgan D, Gregor K, Silver D. 2015. Universal value function approximators, In ICML\nSchmid PJ. 2010. Dynamic mode decomposition for numerical and experimental data. J. Fluid\nMech. 656:5\u201328\nSchmidt M, Lipson H. 2009. Distilling free-form natural laws from experimental data. Science\n324:81\u201385\nSch\u00a8olkopf B, Smola AJ. 2002. Learning with kernels:\nsupport vector machines, regularization,\noptimization, and beyond. MIT Press\nSchwefel HP. 1977. Numerische optimierung von computer-modellen mittels der evolutionsstrate-\ngie.(teil 1, kap. 1-5). Birkh\u00a8auser\nSemeraro O, Lusseyran F, Pastur L, Jordan P. 2016. Qualitative dynamics of wavepackets in tur-\nbulent jets. arXiv preprint arXiv:1608.06750\nSilver D, Huang A, Maddison CJ, Guez A, Sifre L, et al. 2016. Mastering the game of Go with deep\nneural networks and tree search. Nature 529:484\u2013489\nSingh AP, Medida S, Duraisamy K. 2017. Machine-learning-augmented predictive modeling of tur-\nbulent separated \ufb02ows over airfoils. AIAA J. 55:2215\u20132227\nSirovich L. 1987. Turbulence and the dynamics of coherent structures, parts I-III. Q. Appl. Math.\nXLV:561\u2013590\nSirovich L, Kirby M. 1987. A low-dimensional procedure for the characterization of human faces.\nJ. Opt. Soc. Am. A 4:519\u2013524\nSkinner SN, Zare-Behtash H. 2018. State-of-the-art in aerodynamic shape optimisation methods.\nAppl. Soft. Comput. 62:933\u2013962\nStrom B, Brunton SL, Polagye B. 2017. Intracycle angular velocity control of cross-\ufb02ow turbines.\nNat. Energy 2:1\u20139\nThe classic book\nfor reinforcement\nlearning\nSutton RS, Barto AG. 2018. Reinforcement learning: An introduction, vol. 2nd Edi-\ntion. MIT Press\nTaira K, Brunton SL, Dawson S, Rowley CW, Colonius T, et al. 2017. Modal analysis of \ufb02uid \ufb02ows:\nAn overview. AIAA J. 55:4013\u20134041\nTakeishi N, Kawahara Y, Yairi T. 2017. Learning koopman invariant subspaces for dynamic mode\ndecomposition, In Adv. Neural Inf. Process. Syst.\nwww.annualreviews.org \u2022 Machine Learning for Fluid Mechanics\n31\n\n\nTedrake R, Jackowski Z, Cory R, Roberts JW, Hoburg W. 2009. Learning to \ufb02y like a bird, In 14th\nISRR\nTeo C, Lim K, Hong G, Yeo M. 1991. A neural net approach in analysing photographs in PIV.\nIEEE Sys. Man. Cybern. 3:1535\u20131538\nTesauro G. 1992. Practical Issues in Temporal Di\ufb00erence Learning. Mach. Learn. 8:257\u2013277\nAn excellent\nresource linking\nmachine learning\nand Bayesian\ninference\nalgorithms.\nTheodoridis S. 2015. Machine learning: a Bayesian and optimization perspective. Aca-\ndemic Press\nTsiotras P, Mesbahi M. 2017. Toward an algorithmic control theory. J. Guid. Ctrl. Dyn. 40:194\u2013196\nVan Rees WM, Gazzola M, Koumoutsakos P. 2015. Optimal morphokinematics for undulatory\nswimmers at intermediate reynolds numbers. J. Fluid Mech. 775:178\u2013188\nVerma S, Novati G, Koumoutsakos P. 2018. E\ufb03cient collective swimming by harnessing vortices\nthrough deep reinforcement learning. Proc. Natl. Acad. Sci. USA 115\nVlachas PR, Byeon W, Wan ZY, Sapsis TP, Koumoutsakos P. 2018. Data-driven forecasting\nof high-dimensional chaotic systems with long short-term memory networks. Proc. R. Soc. A\n474:20170844\nWan ZY, Vlachas P, Koumoutsakos P, Sapsis T. 2018. Data-assisted reduced-order modeling of\nextreme events in complex dynamical systems. PLoS ONE 13:e0197704\nWang JX, Wu JL, Xiao H. 2017. Physics-informed machine learning approach for reconstructing\nReynolds stress modeling discrepancies based on DNS data. Phys. Rev. Fluids 2:034603\nWang M, Hemati MS. 2017. Detecting exotic wakes with hydrodynamic sensors. arXiv preprint\narXiv:1711.10576\nWehmeyer C, No\u00b4e F. 2018. Time-lagged autoencoders: Deep learning of slow collective variables\nfor molecular kinetics. J. Chem. Phys. 148:1\u20139\nWiener N. 1965. Cybernetics or control and communication in the animal and the machine, vol. 25.\nMIT Press\nWillert CE, Gharib M. 1991. Digital particle image velocimetry. Exp. Fluids 10:181\u2013193\nWilliams MO, Rowley CW, Kevrekidis IG. 2015. A kernel approach to data-driven Koopman spec-\ntral analysis. J. Comp. Dyn. 2:247\u2013265\nWright J, Yang A, Ganesh A, Sastry S, Ma Y. 2009. Robust face recognition via sparse representa-\ntion. IEEE Trans. Pattern Anal. Mach. Intell. 31:210\u2013227\nWu H, Mardt A, Pasquali L, Noe F. 2018. Deep generative markov state models. Adv. Neural Inf.\nProcess. Syst.\nWu X, Moin P. 2008. A direct numerical simulation study on the mean velocity characteristics in\nturbulent pipe \ufb02ow. J. Fluid Mech. 608:81\u2013112\nXiao H, Wu JL, Wang JX, Sun R, Roy C. 2016. Quantifying and reducing model-form uncertain-\nties in Reynolds-averaged Navier\u2013Stokes simulations: A data-driven, physics-informed Bayesian\napproach. J. Comp. Phys. 324:115\u2013136\nXie Y, Franz E, Chu M, Thuerey N. 2018. tempoGAN: A temporally coherent, volumetric GAN for\nsuper-resolution \ufb02uid \ufb02ow. ACM Trans. Graph. 37:95\nYang J, Wright J, Huang TS, Ma Y. 2010. Image super-resolution via sparse representation. IEEE\nTrans. Image Process. 19:2861\u20132873\n32\nBrunton, Noack, and Koumoutsakos\n==================================================",
      "type": "introduction",
      "word_count": 16520
    },
    {
      "title": "ABSTRACT",
      "content": "==================================================\n\nThe \ufb01eld of \ufb02uid mechanics is rapidly advancing, driven by unprece- dented volumes of data from \ufb01eld measurements, experiments and large- scale simulations at multiple spatiotemporal scales. Machine learning o\ufb00ers a wealth of techniques to extract information from data that could be translated into knowledge about the underlying \ufb02uid me- chanics. Moreover, machine learning algorithms can augment domain knowledge and automate tasks related to \ufb02ow control and optimiza- tion. This article presents an overview of past history, current devel- opments, and emerging opportunities of machine learning for \ufb02uid me- chanics. It outlines fundamental machine learning methodologies and discusses their uses for understanding, modeling, optimizing, and con-",
      "type": "abstract",
      "word_count": 107
    }
  ],
  "metadata": {
    "source_file": "data/extracted_texts\\Brunton2019_Machine_Learning_for_Fluid_Mechanics_extracted.txt",
    "total_sections": 3
  }
}